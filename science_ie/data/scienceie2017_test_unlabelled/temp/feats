Tailor-made shaping of microcatheters using three-dimensional printed vessel models for endovascular coil embolization
BackgroundStabilization of microcatheters during coiling after their optimal shaping are key factors for successful endovascular coil embolization of cerebral aneurysms. However, stabilization and optimal shaping of microcatheters are sometimes difficult. Our aim was to introduce “tailor-made” microcatheter shapes for coil embolization using three-dimensional (3D) printed vessel models.MethodSince August 2014, we have been investigating the use of 3D printed models of intracranial arterial aneurysms to produce optimally shaped microcatheters for endovascular coil embolization. Using Digital Imaging and Communication in Medicine data obtained from preoperative cerebral angiography, a vessel model was produced with a 3D printer using acrylic resin. Preoperative planning of microcatheter navigation and shaping were performed using the 3D vessel models. Before the procedure, microcatheter mandrels were bent manually to the intended angle, referring to the vessel model, and then sterilized. The 3D vessel models were also sterilized with plasma and used during the procedure.ResultsTwenty-six patients (27 aneurysms) were treated using a total of 48 microcatheters shaped while referring to the 3D printed vessel model. Of the 48 catheters, only 9 (19%) required modification of the initial shape due to inappropriate positioning of the catheter. Only 29% of the catheter placements required repositioning due to catheter kick back. There were no procedure-related complications, including aneurysm rupture. The responses from assistants to a questionnaire administered after the embolizations on the usefulness of the technique were favorable.ConclusionsTailor-made shaping of microcatheters may facilitate easier and safer procedures in coil embolization of intracranial aneurysm.BackgroundStabilization of microcatheters during coiling after their optimal shaping are key factors for successful endovascular coil embolization of cerebral aneurysms. However, stabilization and optimal shaping of microcatheters are sometimes difficult. Our aim was to introduce “tailor-made” microcatheter shapes for coil embolization using three-dimensional (3D) printed vessel models.MethodSince August 2014, we have been investigating the use of 3D printed models of intracranial arterial aneurysms to produce optimally shaped microcatheters for endovascular coil embolization. Using Digital Imaging and Communication in Medicine data obtained from preoperative cerebral angiography, a vessel model was produced with a 3D printer using acrylic resin. Preoperative planning of microcatheter navigation and shaping were performed using the 3D vessel models. Before the procedure, microcatheter mandrels were bent manually to the intended angle, referring to the vessel model, and then sterilized. The 3D vessel models were also sterilized with plasma and used during the procedure.ResultsTwenty-six patients (27 aneurysms) were treated using a total of 48 microcatheters shaped while referring to the 3D printed vessel model. Of the 48 catheters, only 9 (19%) required modification of the initial shape due to inappropriate positioning of the catheter. Only 29% of the catheter placements required repositioning due to catheter kick back. There were no procedure-related complications, including aneurysm rupture. The responses from assistants to a questionnaire administered after the embolizations on the usefulness of the technique were favorable.ConclusionsTailor-made shaping of microcatheters may facilitate easier and safer procedures in coil embolization of intracranial aneurysm.


The protective role of hydrozincite during initial corrosion of a Cu40Zn alloy in chloride-containing laboratory atmosphere
Hydrozincite, Zn5(CO3)2(OH)6, was recently found to play a key role in reducing corrosion product flaking on Cu–Zn alloys. A fundamental study was undertaken to explore the underlying mechanisms, in particular why hydrozincite can suppress the interaction between chlorides and the alloy surface. Hydrozincite could be formed by exposure of Cu40Zn to air at 70% relative humidity and 1000ppm of CO2 resulting in a surface of decreased wettability. Its presence reduces the initial spreading ability of NaCl-containing droplets and lowers the overall initial corrosion rate when the alloy is exposed to pre-deposited NaCl and wet/dry cycles.


Investigation of dealloying of S phase (Al2CuMg) in AA 2024-T3 aluminium alloy using high resolution 2D and 3D electron imaging
High-resolution 2D and 3D electron microscopy have been employed to investigate the dealloying of S phase (Al2CuMg) particles in an AA 2024-T3 aluminium alloy. Preferential dissolution of magnesium and aluminium produced a sponge-like remnant with nanosize porosity and a copper-rich remnant network. The dealloyed S phase remnant retains a tetragonal structure with a smaller lattice parameter than the S phase. Metallic copper nanoparticles, constituting 4–8% of the dealloyed remnant, are present at the intersections of remnant branches. At the surface of the remnant, a copper layer of ∼2nm thickness is formed, which terminates further dissolution of the less noble elements.


Design and performance of a fast thermal response miniature Chromium Potassium Alum (CPA) salt pill for use in a millikelvin cryocooler
The design and performance of a fast thermal response miniature (24mm outer diameter by 30mm long) Chromium Potassium Alum (CPA) salt pill is described. The need for a fast thermal response has been driven by the development of a continuously operating millikelvin cryocooler (mKCC) which uses 2T superconducting magnets that can be ramped to full field in 30s. The consequence of magnetising and demagnetising the CPA pill in such a short time is that thermal boundary resistance and eddy current heating have a significant impact on the performance of the pill, which was investigated in detail using modelling. The complete design of a prototype CPA pill is described in this paper, including the methods used to minimise thermal boundary resistance and eddy current heating as well as the manufacturing and assembly processes. The performance of the prototype CPA pill operated from a 3.6K bath is presented, demonstrating that a complete CPA cycle (magnetising, cooling to bath and demagnetising) can be accomplished in under 2.5min, with magnetisation and demagnetisation taking just 30s each. The cold finger base temperature of the prototype varies with demagnetisation speed as a consequence of eddy current heating; for a 30s demagnetisation, a base temperature of 161mK is obtained, whilst for a 5min demagnetisation, a base temperature of 149mK was measured (both from a 3.6K and 2T starting position). The measured hold times of the CPA pill at 200mK, 300mK, and 1K are given, proving that the hold time far exceeds the recycle time and demonstrating the potential for continuous operation when two ADRs are used in a tandem configuration. The ease and speed at which the CPA pill temperature can be changed and controlled when stepping between operating temperatures in the range of 200mK to 4K using a servo control program is also shown, once again highlighting the excellent thermal response of the pill. All of the test results are in good agreement with the modelling used to design the CPA pill, giving good confidence in our ability to understand and estimate the effects of eddy current heating and thermal boundary resistance. To conclude, the design for the CPA pill to be used in the mKCC (which is heavily based on the design of the prototype) is presented.


Batch screening of commercial serial flash-memory integrated circuits for low-temperature applications
We present comprehensive results on the experimentally measured performance of commercial serial flash-memory integrated circuits (ICs) over a wide temperature range (−196°C to 25°C). We also address endurance issues because our intended low-temperature application is electronics related to long-term storage of biological material. We compared six batches of flash-memory ICs, manufactured between 2007 and 2012. Test results reveal a batch-to-batch variation of the pass rate. Typically, programming times increase by a factor of 4–6 at −196°C. The practical relevance of our results is discussed.


Performance of a fast response miniature Adiabatic Demagnetisation Refrigerator using a single crystal tungsten magnetoresistive heat switch
The performance of a fast thermal response miniature Adiabatic Demagnetisation Refrigerator (ADR) is presented. The miniature ADR is comprised of a fast thermal response Chromium Potassium Alum (CPA) salt pill, two superconducting magnets and unconventionally, a single crystal tungsten magnetoresistive (MR) heat switch. The development of this ADR is a result of the ongoing development of a continuously operating millikelvin cryocooler (mKCC), which will use only magnetoresistive heat switches. The design and performance of the MR heat switch developed for the mKCC and used in the miniature ADR is presented in this paper; the heat switch has a measured Residual Resistivity Ratio of 32,000±3000 and an estimated switching ratio (on thermal conductivity divided by the off thermal conductivity) of 15,200 at 3.6K and 38,800 at 0.2K when using a 3T magnetic field. The performance of the miniature ADR operating from a 3.6K bath is presented, demonstrating that a complete cycle (magnetisation, cooling to the bath and demagnetisation) can be accomplished in 82s. A magnet current step test, conducted when the ADR is cold and fully demagnetised, has shown the thermal response of the ADR to be sub-second. The measured hold times of the ADR with just parasitic heat load are given, ranging from 3min at 0.2K with 13.14μW of parasitics, to 924min at 3K with 4.55μW of parasitics. The cooling power has been measured for operating temperatures in the range 0.25–3K by applying an additional heat load to the ADR via a heater, in order to reduce the hold time to 3min (i.e. approximately double the recycle time); the maximum cooling power of the miniature ADR (in addition to parasitic load) when operating at 250mK is 20μW, which increases to 45μW at 300mK and continues to increase linearly to nearly 1.1mW at 3K. To conclude, the predicted performance of a tandem continuous ADR utilising two of the miniature ADRs is presented.


A task-based evaluation of combined set and network visualization
This paper addresses the problem of how best to visualize network data grouped into overlapping sets. We address it by evaluating various existing techniques alongside a new technique. Such data arise in many areas, including social network analysis, gene expression data, and crime analysis. We begin by investigating the strengths and weakness of four existing techniques, namely Bubble Sets, EulerView, KelpFusion, and LineSets, using principles from psychology and known layout guides. Using insights gained, we propose a new technique, SetNet, that may overcome limitations of earlier methods. We conducted a comparative crowdsourced user study to evaluate all five techniques based on tasks that require information from both the network and the sets. We established that EulerView and SetNet, both of which draw the sets first, yield significantly faster user responses than Bubble Sets, KelpFusion and LineSets, all of which draw the network first.This paper addresses the problem of how best to visualize network data grouped into overlapping sets. We address it by evaluating various existing techniques alongside a new technique. Such data arise in many areas, including social network analysis, gene expression data, and crime analysis. We begin by investigating the strengths and weakness of four existing techniques, namely Bubble Sets, EulerView, KelpFusion, and LineSets, using principles from psychology and known layout guides. Using insights gained, we propose a new technique, SetNet, that may overcome limitations of earlier methods. We conducted a comparative crowdsourced user study to evaluate all five techniques based on tasks that require information from both the network and the sets. We established that EulerView and SetNet, both of which draw the sets first, yield significantly faster user responses than Bubble Sets, KelpFusion and LineSets, all of which draw the network first.


High temperature phase transition of mixed (PuO2+ThO2) investigated by laser melting
A laser heating approach combined with fast pyrometry in a thermal arrest method was used to provide new data for the melting/solidification phase transition in mixed (PuO2+ThO2) at high temperature. At low concentration of ThO2 in PuO2 a minimum in the solidification temperature in the pseudo binary (PuO2+ThO2) was observed. The minimum was found around a composition with 5mol% ThO2. Phase transition temperatures of other compositions are closer to an ideal solution behaviour. To detect changes in the material a complete investigation with electron microscopy, Raman spectroscopy and powder X-ray diffraction was done. Raman vibration modes were found, that are characteristic for materials containing PuO2, and high temperature segregation effects during solidification were described. The results obtained in the present work are compared to other mixed actinide dioxides and compared to the ideal solution case for this system. The presented results show the importance of the high-temperature oxygen chemistry in this actinide oxide phase.


Efficient simulation of cardiac electrical propagation using high order finite elements
We present an application of high order hierarchical finite elements for the efficient approximation of solutions to the cardiac monodomain problem. We detail the hurdles which must be overcome in order to achieve theoretically-optimal errors in the approximations generated, including the choice of method for approximating the solution to the cardiac cell model component. We place our work on a solid theoretical foundation and show that it can greatly improve the accuracy in the approximation which can be achieved in a given amount of processor time. Our results demonstrate superior accuracy over linear finite elements at a cheaper computational cost and thus indicate the potential indispensability of our approach for large-scale cardiac simulation.


Boundary element dynamical energy analysis: A versatile method for solving two or three dimensional wave problems in the high frequency limit
Dynamical energy analysis was recently introduced as a new method for determining the distribution of mechanical and acoustic wave energy in complex built up structures. The technique interpolates between standard statistical energy analysis and full ray tracing, containing both of these methods as limiting cases. As such the applicability of the method is wide ranging and additionally includes the numerical modelling of problems in optics and more generally of linear wave problems in electromagnetics. In this work we consider a new approach to the method with enhanced versatility, enabling three-dimensional problems to be handled in a straightforward manner. The main challenge is the high dimensionality of the problem: we determine the wave energy density both as a function of the spatial coordinate and momentum (or direction) space. The momentum variables are expressed in separable (polar) coordinates facilitating the use of products of univariate basis expansions. However this is not the case for the spatial argument and so we propose to make use of automated mesh generating routines to both localise the approximation, allowing quadrature costs to be kept moderate, and give versatility in the code for different geometric configurations.


An efficient preconditioner for monolithically-coupled large-displacement fluid–structure interaction problems with pseudo-solid mesh updates
We present a block preconditioner for the efficient solution of the linear systems that arise when employing Newton’s method to solve monolithically-coupled large-displacement fluid–structure interaction problems in which the update of the moving fluid mesh is performed by the equations of large-displacement elasticity. Following a theoretical analysis of the preconditioner, we propose an efficient implementation that yields a solver with near-optimal computational cost, in the sense that the time for the solution of the linear systems scales approximately linearly with the number of unknowns. We evaluate the performance of the preconditioner in selected two- and three-dimensional test problems.


Optimized explicit finite-difference schemes for spatial derivatives using maximum norm
Conventional explicit finite-difference methods have difficulties in handling high-frequency components due to strong numerical dispersions. One can reduce the numerical dispersions by optimizing the constant coefficients of the finite-difference operator. Different from traditional optimized schemes that use the 2-norm and the least squares, we propose to construct the objective functions using the maximum norm and solve the objective functions using the simulated annealing algorithm. Both theoretical analyses and numerical experiments show that our optimized scheme is superior to traditional optimized schemes with regard to the following three aspects. First, it provides us with much more flexibility when designing the objective functions; thus we can use various possible forms and contents to make the objective functions more reasonable. Second, it allows for tighter error limitation, which is shown to be necessary to avoid rapid error accumulations for simulations on large-scale models with long travel times. Finally, it is powerful to obtain the optimized coefficients that are much closer to the theoretical limits, which means greater savings in computational efforts and memory demand.


An enhanced Immersed Structural Potential Method for fluid–structure interaction
Within the group of immersed boundary methods employed for the numerical simulation of fluid–structure interaction problems, the Immersed Structural Potential Method (ISPM) was recently introduced (Gil et al., 2010) [1] in order to overcome some of the shortcomings of existing immersed methodologies. In the ISPM, an incompressible immersed solid is modelled as a deviatoric strain energy functional whose spatial gradient defines a fluid–structure interaction force field in the Navier–Stokes equations used to resolve the underlying incompressible Newtonian viscous fluid. In this paper, two enhancements of the methodology are presented. First, the introduction of a new family of spline-based kernel functions for the transfer of information between both physics. In contrast to classical IBM kernels, these new kernels are shown not to introduce spurious oscillations in the solution. Second, the use of tensorised Gaussian quadrature rules that allow for accurate and efficient numerical integration of the immersed structural potential. A series of numerical examples will be presented in order to demonstrate the capabilities of the enhanced methodology and to draw some key comparisons against other existing immersed methodologies in terms of accuracy, preservation of the incompressibility constraint and computational speed.


An approach for treating contact surfaces in Lagrangian cell-centered hydrodynamics
A new method is presented for modeling contact surfaces in Lagrangian cell-centered hydrodynamics (CCH). The contact method solves a multi-directional Riemann-like problem at each penetrating or touching node along the contact surface. The velocity of a penetrating or touching node and the corresponding forces are explicitly calculated using the Riemann-like nodal solver. The contact method works with material strength and allows surfaces to impact, slide, and separate. Results are presented for several test problems involving both gases and materials with strength. The new contact surface approach extends the modeling capabilities of CCH.


Runge–Kutta IMEX schemes for the Horizontally Explicit/Vertically Implicit (HEVI) solution of wave equations
Many operational weather forecasting centres use semi-implicit time-stepping schemes because of their good efficiency. However, as computers become ever more parallel, horizontally explicit solutions of the equations of atmospheric motion might become an attractive alternative due to the additional inter-processor communication of implicit methods. Implicit and explicit (IMEX) time-stepping schemes have long been combined in models of the atmosphere using semi-implicit, split-explicit or HEVI splitting. However, most studies of the accuracy and stability of IMEX schemes have been limited to the parabolic case of advection–diffusion equations. We demonstrate how a number of Runge–Kutta IMEX schemes can be used to solve hyperbolic wave equations either semi-implicitly or HEVI. A new form of HEVI splitting is proposed, UfPreb, which dramatically improves accuracy and stability of simulations of gravity waves in stratified flow. As a consequence it is found that there are HEVI schemes that do not lose accuracy in comparison to semi-implicit ones.The stability limits of a number of variations of trapezoidal implicit and some Runge–Kutta IMEX schemes are found and the schemes are tested on two vertical slice cases using the compressible Boussinesq equations split into various combinations of implicit and explicit terms. Some of the Runge–Kutta schemes are found to be beneficial over trapezoidal, especially since they damp high frequencies without dropping to first-order accuracy. We test schemes that are not formally accurate for stiff systems but in stiff limits (nearly incompressible) and find that they can perform well. The scheme ARK2(2,3,2) performs the best in the tests.


Fluid simulations with atomistic resolution: a hybrid multiscale method with field-wise coupling
We present a new hybrid method for simulating dense fluid systems that exhibit multiscale behaviour, in particular, systems in which a Navier–Stokes model may not be valid in parts of the computational domain. We apply molecular dynamics as a local microscopic refinement for correcting the Navier–Stokes constitutive approximation in the bulk of the domain, as well as providing a direct measurement of velocity slip at bounding surfaces. Our hybrid approach differs from existing techniques, such as the heterogeneous multiscale method (HMM), in some fundamental respects. In our method, the individual molecular solvers, which provide information to the macro model, are not coupled with the continuum grid at nodes (i.e. point-wise coupling), instead coupling occurs over distributed heterogeneous fields (here referred to as field-wise coupling). This affords two major advantages. Whereas point-wise coupled HMM is limited to regions of flow that are highly scale-separated in all spatial directions (i.e. where the state of non-equilibrium in the fluid can be adequately described by a single strain tensor and temperature gradient vector), our field-wise coupled HMM has no such limitations and so can be applied to flows with arbitrarily-varying degrees of scale separation (e.g. flow from a large reservoir into a nano-channel). The second major advantage is that the position of molecular elements does not need to be collocated with nodes of the continuum grid, which means that the resolution of the microscopic correction can be adjusted independently of the resolution of the continuum model. This in turn means the computational cost and accuracy of the molecular correction can be independently controlled and optimised. The macroscopic constraints on the individual molecular solvers are artificial body-force distributions, used in conjunction with standard periodicity. We test our hybrid method on the Poiseuille flow problem for both Newtonian (Lennard-Jones) and non-Newtonian (FENE) fluids. The multiscale results are validated with expensive full-scale molecular dynamics simulations of the same case. Very close agreement is obtained for all cases, with as few as two micro elements required to accurately capture both the Newtonian and non-Newtonian flowfields. Our multiscale method converges very quickly (within 3–4 iterations) and is an order of magnitude more computationally efficient than the full-scale simulation.


A numerical modelling of gas exchange mechanisms between air and turbulent water with an aquarium chemical reaction
This paper proposes a new numerical modelling to examine environmental chemodynamics of a gaseous material exchanged between the air and turbulent water phases across a gas–liquid interface, followed by an aquarium chemical reaction. This study uses an extended concept of a two-compartment model, and assumes two physicochemical substeps to approximate the gas exchange processes. The first substep is the gas–liquid equilibrium between the air and water phases, A(g)⇌A(aq), with Henryʼs law constant H. The second is a first-order irreversible chemical reaction in turbulent water, A(aq)+H2O→B(aq)+H+ with a chemical reaction rate κA. A direct numerical simulation (DNS) technique has been employed to obtain details of the gas exchange mechanisms and the chemical reaction in the water compartment, while zero velocity and uniform concentration of A is considered in the air compartment. The study uses the different Schmidt numbers between 1 and 8, and six nondimensional chemical reaction rates between 10−∞(≈0) to 101 at a fixed Reynolds number. It focuses on the effects of the Schmidt number and the chemical reaction rate on fundamental mechanisms of the gas exchange processes across the interface.


Hybrid continuum–molecular modelling of multiscale internal gas flows
We develop and apply an efficient multiscale method for simulating a large class of low-speed internal rarefied gas flows. The method is an extension of the hybrid atomistic–continuum approach proposed by Borg et al. (2013) [28] for the simulation of micro/nano flows of high-aspect ratio. The major new extensions are: (1) incorporation of fluid compressibility; (2) implementation using the direct simulation Monte Carlo (DSMC) method for dilute rarefied gas flows, and (3) application to a broader range of geometries, including periodic, non-periodic, pressure-driven, gravity-driven and shear-driven internal flows. The multiscale method is applied to micro-scale gas flows through a periodic converging–diverging channel (driven by an external acceleration) and a non-periodic channel with a bend (driven by a pressure difference), as well as the flow between two eccentric cylinders (with the inner rotating relative to the outer). In all these cases there exists a wide variation of Knudsen number within the geometries, as well as substantial compressibility despite the Mach number being very low. For validation purposes, our multiscale simulation results are compared to those obtained from full-scale DSMC simulations: very close agreement is obtained in all cases for all flow variables considered. Our multiscale simulation is an order of magnitude more computationally efficient than the full-scale DSMC for the first and second test cases, and two orders of magnitude more efficient for the third case.


High-order spectral/hp element discretisation for reaction–diffusion problems on surfaces: Application to cardiac electrophysiology
We present a numerical discretisation of an embedded two-dimensional manifold using high-order continuous Galerkin spectral/hp elements, which provide exponential convergence of the solution with increasing polynomial order, while retaining geometric flexibility in the representation of the domain. Our work is motivated by applications in cardiac electrophysiology where sharp gradients in the solution benefit from the high-order discretisation, while the computational cost of anatomically-realistic models can be significantly reduced through the surface representation and use of high-order methods. We describe and validate our discretisation and provide a demonstration of its application to modelling electrochemical propagation across a human left atrium.


Pairwise adaptive thermostats for improved accuracy and stability in dissipative particle dynamics
We examine the formulation and numerical treatment of dissipative particle dynamics (DPD) and momentum-conserving molecular dynamics. We show that it is possible to improve both the accuracy and the stability of DPD by employing a pairwise adaptive Langevin thermostat that precisely matches the dynamical characteristics of DPD simulations (e.g., autocorrelation functions) while automatically correcting thermodynamic averages using a negative feedback loop. In the low friction regime, it is possible to replace DPD by a simpler momentum-conserving variant of the Nosé–Hoover–Langevin method based on thermostatting only pairwise interactions; we show that this method has an extra order of accuracy for an important class of observables (a superconvergence result), while also allowing larger timesteps than alternatives. All the methods mentioned in the article are easily implemented. Numerical experiments are performed in both equilibrium and nonequilibrium settings; using Lees–Edwards boundary conditions to induce shear flow.We examine the formulation and numerical treatment of dissipative particle dynamics (DPD) and momentum-conserving molecular dynamics. We show that it is possible to improve both the accuracy and the stability of DPD by employing a pairwise adaptive Langevin thermostat that precisely matches the dynamical characteristics of DPD simulations (e.g., autocorrelation functions) while automatically correcting thermodynamic averages using a negative feedback loop. In the low friction regime, it is possible to replace DPD by a simpler momentum-conserving variant of the Nosé–Hoover–Langevin method based on thermostatting only pairwise interactions; we show that this method has an extra order of accuracy for an important class of observables (a superconvergence result), while also allowing larger timesteps than alternatives. All the methods mentioned in the article are easily implemented. Numerical experiments are performed in both equilibrium and nonequilibrium settings; using Lees–Edwards boundary conditions to induce shear flow.


Modular chemical tools for advanced macromolecular engineering
Contemporary polymer science requires, more than ever, simple and efficient chemical reactions for constructing complex macromolecular or supramolecular structures. The present feature article highlights our recent efforts to develop modular synthetic platforms in macromolecular synthesis. As examples, the macromolecular engineering possibilities of two “click” reactions (i) the copper-catalyzed cycloaddition of azides and terminal alkynes and (ii) the radical addition of mercaptans onto vinyl double bonds are discussed in detail herein.Contemporary polymer science requires, more than ever, simple and efficient chemical reactions for constructing complex macromolecular or supramolecular structures. The present feature article highlights our recent efforts to develop modular synthetic platforms in macromolecular synthesis. As examples, the macromolecular engineering possibilities of two “click” reactions (i) the copper-catalyzed cycloaddition of azides and terminal alkynes and (ii) the radical addition of mercaptans onto vinyl double bonds are discussed in detail herein.


Structure–mechanical property correlations of model siloxane elastomers with controlled network topology
Graphical abstract


Hierarchical nanophase-separated structures created by precisely-designed polymers with complexity
Graphical abstract


Retarded anionic polymerization (RAP) of styrene and dienes
Graphical abstract


Step-growth polymerization and ‘click’ chemistry: The oldest polymers rejuvenated
Graphical abstract


Imidazole- and imidazolium-containing polymers for biology and material science applications
Graphical abstract


The prediction of metastable impact electronic spectra (MIES): perfect and defective MgO(001) surfaces by state-of-the-art methods
We re-examine the theory of metastable impact electron spectroscopy (MIES) in its application to insulating surfaces. This suggests a quantitative approach which takes advantage of recent developments in highly efficient many-electron computational techniques. It gives a basis to the interpretation of experimental MIES spectra for perfect and defective surfaces. Our method is based on a static approach to predicting Auger de-excitation (AD) rates of He∗(1s2s) projectiles. A key quantity is the surface density of states (DOS) projected on the 1s orbital of the He∗ atom, which is calculated along its trajectory. We use density functional theory within both supercell geometry and embedded cluster models to calculate MIES spectra for the perfect MgO surface and for an MgO surface with different concentrations of adsorbed oxygen atoms. First we calculate the Auger de-excitation rates at various positions of the projectile above the surface. To predict MIES spectra, we integrate over projectile trajectories, with a subsequent weighted averaging with respect to various lateral positions of He∗ above the MgO surface unit cell. It is important to examine final-state effects for a correct comparison between theory and experiment, especially when there are localised defect states.We re-examine the theory of metastable impact electron spectroscopy (MIES) in its application to insulating surfaces. This suggests a quantitative approach which takes advantage of recent developments in highly efficient many-electron computational techniques. It gives a basis to the interpretation of experimental MIES spectra for perfect and defective surfaces. Our method is based on a static approach to predicting Auger de-excitation (AD) rates of He∗(1s2s) projectiles. A key quantity is the surface density of states (DOS) projected on the 1s orbital of the He∗ atom, which is calculated along its trajectory. We use density functional theory within both supercell geometry and embedded cluster models to calculate MIES spectra for the perfect MgO surface and for an MgO surface with different concentrations of adsorbed oxygen atoms. First we calculate the Auger de-excitation rates at various positions of the projectile above the surface. To predict MIES spectra, we integrate over projectile trajectories, with a subsequent weighted averaging with respect to various lateral positions of He∗ above the MgO surface unit cell. It is important to examine final-state effects for a correct comparison between theory and experiment, especially when there are localised defect states.


Integration of Google Maps/Earth with microscale meteorology models and data visualization
The Google Maps/Earth GIS has been integrated with a microscale meteorological model to improve the system's functionality and ease of use. Almost all the components of the model system, including the terrain data processing, morphological data generation, meteorological data gathering and initialization, and displaying/visualizing the model results, have been improved by using this approach. Different from the traditional stand-along model system, this novel system takes advantages of enormous resources in map and image data retrieving/handling, four-dimensional (space and time) data visualization, overlaying, and many other advanced GIS features that the Google Maps/Earth platform has to offer. We have developed modular components for all of the model system controls and data processing programs which are glued together with the JavaScript language and KML/XML data. We have also developed small modular software using the Google application program interface to convert the model results and intermediate data for visualizations and animations. Capabilities such as high-resolution image, street view, and 3D buildings in the Google Earth/Map are also used to quickly generate small-scale vegetation and building morphology data that are required for the microscale meteorological models. This system has also been applied to visualize the data from other instruments such as Doppler wind lidars. Because of the tight integration of the internet based GIS and a microscale meteorology model, the model system is more versatile, intuitive, and user-friendly than a stand-along system we had developed before. This kind of system will enhance the user experience and also help researchers to explore new phenomena in fine-scale meteorology.The Google Maps/Earth GIS has been integrated with a microscale meteorological model to improve the system's functionality and ease of use. Almost all the components of the model system, including the terrain data processing, morphological data generation, meteorological data gathering and initialization, and displaying/visualizing the model results, have been improved by using this approach. Different from the traditional stand-along model system, this novel system takes advantages of enormous resources in map and image data retrieving/handling, four-dimensional (space and time) data visualization, overlaying, and many other advanced GIS features that the Google Maps/Earth platform has to offer. We have developed modular components for all of the model system controls and data processing programs which are glued together with the JavaScript language and KML/XML data. We have also developed small modular software using the Google application program interface to convert the model results and intermediate data for visualizations and animations. Capabilities such as high-resolution image, street view, and 3D buildings in the Google Earth/Map are also used to quickly generate small-scale vegetation and building morphology data that are required for the microscale meteorological models. This system has also been applied to visualize the data from other instruments such as Doppler wind lidars. Because of the tight integration of the internet based GIS and a microscale meteorology model, the model system is more versatile, intuitive, and user-friendly than a stand-along system we had developed before. This kind of system will enhance the user experience and also help researchers to explore new phenomena in fine-scale meteorology.


Large-scale seismic signal analysis with Hadoop
In seismology, waveform cross correlation has been used for years to produce high-precision hypocenter locations and for sensitive detectors. Because correlated seismograms generally are found only at small hypocenter separation distances, correlation detectors have historically been reserved for spotlight purposes. However, many regions have been found to produce large numbers of correlated seismograms, and there is growing interest in building next-generation pipelines that employ correlation as a core part of their operation. In an effort to better understand the distribution and behavior of correlated seismic events, we have cross correlated a global dataset consisting of over 300 million seismograms. This was done using a conventional distributed cluster, and required 42 days. In anticipation of processing much larger datasets, we have re-architected the system to run as a series of MapReduce jobs on a Hadoop cluster. In doing so we achieved a factor of 19 performance increase on a test dataset. We found that fundamental algorithmic transformations were required to achieve the maximum performance increase. Whereas in the original IO-bound implementation, we went to great lengths to minimize IO, in the Hadoop implementation where IO is cheap, we were able to greatly increase the parallelism of our algorithms by performing a tiered series of very fine-grained (highly parallelizable) transformations on the data. Each of these MapReduce jobs required reading and writing large amounts of data. But, because IO is very fast, and because the fine-grained computations could be handled extremely quickly by the mappers, the net was a large performance gain.In seismology, waveform cross correlation has been used for years to produce high-precision hypocenter locations and for sensitive detectors. Because correlated seismograms generally are found only at small hypocenter separation distances, correlation detectors have historically been reserved for spotlight purposes. However, many regions have been found to produce large numbers of correlated seismograms, and there is growing interest in building next-generation pipelines that employ correlation as a core part of their operation. In an effort to better understand the distribution and behavior of correlated seismic events, we have cross correlated a global dataset consisting of over 300 million seismograms. This was done using a conventional distributed cluster, and required 42 days. In anticipation of processing much larger datasets, we have re-architected the system to run as a series of MapReduce jobs on a Hadoop cluster. In doing so we achieved a factor of 19 performance increase on a test dataset. We found that fundamental algorithmic transformations were required to achieve the maximum performance increase. Whereas in the original IO-bound implementation, we went to great lengths to minimize IO, in the Hadoop implementation where IO is cheap, we were able to greatly increase the parallelism of our algorithms by performing a tiered series of very fine-grained (highly parallelizable) transformations on the data. Each of these MapReduce jobs required reading and writing large amounts of data. But, because IO is very fast, and because the fine-grained computations could be handled extremely quickly by the mappers, the net was a large performance gain.


A progressive black top hat transformation algorithm for estimating valley volumes on Mars
The depth of valley incision and valley volume are important parameters in understanding the geologic history of early Mars, because they are related to the amount sediments eroded and the quantity of water needed to create the valley networks (VNs). With readily available digital elevation model (DEM) data, the Black Top Hat (BTH) transformation, an image processing technique for extracting dark features on a variable background, has been applied to DEM data to extract valley depth and estimate valley volume. Previous studies typically use a single window size for extracting the valley features and a single threshold value for removing noise, resulting in finer features such as tributaries not being extracted and underestimation of valley volume. Inspired by similar algorithms used in LiDAR data analysis to remove above-ground features to obtain bare-earth topography, here we propose a progressive BTH (PBTH) transformation algorithm, where the window size is progressively increased to extract valleys of different orders. In addition, a slope factor is introduced so that the noise threshold can be automatically adjusted for windows with different sizes. Independently derived VN lines were used to select mask polygons that spatially overlap the VN lines. Volume is calculated as the sum of valley depth within the selected mask multiplied by cell area. Application of the PBTH to a simulated landform (for which the amount of erosion is known) achieved an overall relative accuracy of 96%, in comparison with only 78% for BTH. Application of PBTH to Ma’adim Vallies on Mars not only produced total volume estimates consistent with previous studies, but also revealed the detailed spatial distribution of valley depth. The highly automated PBTH algorithm shows great promise for estimating the volume of VN on Mars on global scale, which is important for understanding its early hydrologic cycle.The depth of valley incision and valley volume are important parameters in understanding the geologic history of early Mars, because they are related to the amount sediments eroded and the quantity of water needed to create the valley networks (VNs). With readily available digital elevation model (DEM) data, the Black Top Hat (BTH) transformation, an image processing technique for extracting dark features on a variable background, has been applied to DEM data to extract valley depth and estimate valley volume. Previous studies typically use a single window size for extracting the valley features and a single threshold value for removing noise, resulting in finer features such as tributaries not being extracted and underestimation of valley volume. Inspired by similar algorithms used in LiDAR data analysis to remove above-ground features to obtain bare-earth topography, here we propose a progressive BTH (PBTH) transformation algorithm, where the window size is progressively increased to extract valleys of different orders. In addition, a slope factor is introduced so that the noise threshold can be automatically adjusted for windows with different sizes. Independently derived VN lines were used to select mask polygons that spatially overlap the VN lines. Volume is calculated as the sum of valley depth within the selected mask multiplied by cell area. Application of the PBTH to a simulated landform (for which the amount of erosion is known) achieved an overall relative accuracy of 96%, in comparison with only 78% for BTH. Application of PBTH to Ma’adim Vallies on Mars not only produced total volume estimates consistent with previous studies, but also revealed the detailed spatial distribution of valley depth. The highly automated PBTH algorithm shows great promise for estimating the volume of VN on Mars on global scale, which is important for understanding its early hydrologic cycle.


Building the hybrid organisation through ERP and enterprise social software
This research traces the implementation of an information system in the form of ERP modules covering tenant and contract management in a Chinese service company. Misalignments between the ERP system specification and user needs led to the adoption of informal processes within the organisation. These processes are facilitated within an informal organisational structure and are based on human interactions undertaken within the formal organisation. Rather than to attempt to suppress the emergence of the informal organisation the company decided to channel the energies of staff involved in informal processes towards organisational goals. The company achieved this by harnessing the capabilities of what we term a hybrid ERP system, combining the functionality of a traditional (formal) ERP installation with the capabilities of Enterprise Social Software (ESS). However the company recognised that the successful operation of the hybrid ERP system would require a number of changes in organisational design in areas such as reporting structures and communication channels. A narrative provided by interviews with company personnel is thematised around the formal and informal characteristics of the organisation as defined in the literature. This leads to a definition of the characteristics of the hybrid organisation and strategies for enabling a hybrid organisation, facilitated by a hybrid ERP system, which directs formal and informal behaviour towards organisational goals and provides a template for future hybrid implementations.


Generation of hypoallergenic neoglycoconjugates for dendritic cell targeted vaccination: A novel tool for specific immunotherapy
Graphical abstract


Mesoporous silica-supported lipid bilayers (protocells) for DNA cargo delivery to the spinal cord
Graphical abstract


Inertial cavitation to non-invasively trigger and monitor intratumoral release of drug from intravenously delivered liposomes
Graphical abstract


Exploring cryogenic focused ion beam milling as a Group III–V device fabrication tool
In this paper, we compare the features observed on a Group III–V strained layer superlattice (SLS) materials system as a result of room temperature Ga+ focused ion beam (FIB) milling to the features observed as a result of cryogenic FIB (cryo-FIB) milling at –135°C under the same beam conditions (30kV:1nA). The features on the cryo-FIB milled material were observed both when the material was still cold and after it returned to room temperature. Although cryo-FIB milling yielded patterned features that were initially cleaner than comparable features defined by FIB milling at room temperature, we found that both room temperature FIB milling and cryo-FIB milling with subsequent sample warm-up resulted in the formation of Group III enriched features. These findings suggest that the structural and chemical properties of features fabricated by cryo-FIB milling are temperature-dependent, which is an important consideration when it comes to device fabrication. These dependencies will need to be better understood and controlled if cryo-FIB milling is to have future applications in this area.In this paper, we compare the features observed on a Group III–V strained layer superlattice (SLS) materials system as a result of room temperature Ga+ focused ion beam (FIB) milling to the features observed as a result of cryogenic FIB (cryo-FIB) milling at –135°C under the same beam conditions (30kV:1nA). The features on the cryo-FIB milled material were observed both when the material was still cold and after it returned to room temperature. Although cryo-FIB milling yielded patterned features that were initially cleaner than comparable features defined by FIB milling at room temperature, we found that both room temperature FIB milling and cryo-FIB milling with subsequent sample warm-up resulted in the formation of Group III enriched features. These findings suggest that the structural and chemical properties of features fabricated by cryo-FIB milling are temperature-dependent, which is an important consideration when it comes to device fabrication. These dependencies will need to be better understood and controlled if cryo-FIB milling is to have future applications in this area.


Optical and magnetic properties of mixed crystal Ti0.95Ni0.05O2 films deposited on Si substrates by sol–gel method
Ni-doped mixed crystal TiO2 films, Ti0.95Ni0.05O2, were fabricated on Si(100) substrates by sol–gel process. The influences of annealing times on the structural, optical and magnetic properties were investigated. X-ray diffraction measurement indicates that all the films include anatase and rutile phases. The optical constants were obtained by fitting ellipsometric spectra with Adachi's dielectric function model. With increasing rutile content, both the refractive index and the extinction coefficient of the films increase, but the optical band gap EOBG is reduced. The refractive index at 600nm abides by Drude's refractive index model with increasing rutile fraction. The magnetic evolution of the films is from ferromagnetic, to paramagnetic and then ferromagnetic states with increasing rutile fraction, which may be related to the magnetic polarons in the Ni-doped TiO2 films. The results indicate that optical and magnetic properties of Ni-doped TiO2 films can be tuned by controlling phase fraction.Ni-doped mixed crystal TiO2 films, Ti0.95Ni0.05O2, were fabricated on Si(100) substrates by sol–gel process. The influences of annealing times on the structural, optical and magnetic properties were investigated. X-ray diffraction measurement indicates that all the films include anatase and rutile phases. The optical constants were obtained by fitting ellipsometric spectra with Adachi's dielectric function model. With increasing rutile content, both the refractive index and the extinction coefficient of the films increase, but the optical band gap EOBG is reduced. The refractive index at 600nm abides by Drude's refractive index model with increasing rutile fraction. The magnetic evolution of the films is from ferromagnetic, to paramagnetic and then ferromagnetic states with increasing rutile fraction, which may be related to the magnetic polarons in the Ni-doped TiO2 films. The results indicate that optical and magnetic properties of Ni-doped TiO2 films can be tuned by controlling phase fraction.


A composite anodizing coating containing superfine Al2O3 particles on AZ31 magnesium alloy
Anodic coatings with and without superfine Al2O3 particles were prepared on AZ31 magnesium alloy by anodizing in an environmentally friendly alkaline solution. The microstructure and morphology of the coatings were analyzed using X-ray diffraction and scanning electron microscopy equipped with energy dispersive spectroscopy. The corrosion resistance of the uncoated AZ31 substrate and the anodic coatings was evaluated in 3.5% NaCl solution through potentiodynamic polarization tests. Friction and wear tests were performed to evaluate the wear resistance of the samples. The results show that the composite oxide coating has better corrosion resistance than the coating without Al2O3 nanoparticles. The microhardness of the composite coating with reinforced Al2O3 nanoparticles is up to 358HV. When rubbed at 10N load for 3min during sliding against GCr15 at ambient temperature, the wear loss of the film was about 0.04mm3, which is about one-tenth of that of the anodizing coating without nanoparticles. Therefore, the composite anodizing coating with Al2O3 nanoparticles shows better anti-corrosion and anti-wear properties than the coating without Al2O3 nanoparticles.Anodic coatings with and without superfine Al2O3 particles were prepared on AZ31 magnesium alloy by anodizing in an environmentally friendly alkaline solution. The microstructure and morphology of the coatings were analyzed using X-ray diffraction and scanning electron microscopy equipped with energy dispersive spectroscopy. The corrosion resistance of the uncoated AZ31 substrate and the anodic coatings was evaluated in 3.5% NaCl solution through potentiodynamic polarization tests. Friction and wear tests were performed to evaluate the wear resistance of the samples. The results show that the composite oxide coating has better corrosion resistance than the coating without Al2O3 nanoparticles. The microhardness of the composite coating with reinforced Al2O3 nanoparticles is up to 358HV. When rubbed at 10N load for 3min during sliding against GCr15 at ambient temperature, the wear loss of the film was about 0.04mm3, which is about one-tenth of that of the anodizing coating without nanoparticles. Therefore, the composite anodizing coating with Al2O3 nanoparticles shows better anti-corrosion and anti-wear properties than the coating without Al2O3 nanoparticles.


Performance of functionally graded plates under localised transverse loading
This paper presents a study of the bending of an isotropic functionally graded plate under localised transverse load through a combination of analytical and computational means. The analytical modelling is based on the recently developed three-dimensional elasticity solution, expanded to cover different loading types, whilst the Finite Element model uses graded isoparametric elements. The plate under consideration is assumed to be simply supported, with Young’s and shear moduli varying exponentially through the thickness and the Poisson’s ratio constant. Comparative analysis of stress and displacement fields in functionally graded and homogeneous plates subjected to uniformly distributed and patch loadings is carried out.This paper presents a study of the bending of an isotropic functionally graded plate under localised transverse load through a combination of analytical and computational means. The analytical modelling is based on the recently developed three-dimensional elasticity solution, expanded to cover different loading types, whilst the Finite Element model uses graded isoparametric elements. The plate under consideration is assumed to be simply supported, with Young’s and shear moduli varying exponentially through the thickness and the Poisson’s ratio constant. Comparative analysis of stress and displacement fields in functionally graded and homogeneous plates subjected to uniformly distributed and patch loadings is carried out.


Crashworthiness characteristics investigation of silk/epoxy composite square tubes
This research concentrates on the evaluation of crashworthiness characteristics of natural silk/epoxy composite square tubes energy-absorbers. Composite laminate specimens were subjected to static axial compression load and experimental evaluation of the energy absorption capability of silk/epoxy composite. Specimens were in the form of square cross-sections with the dimension of 80mm×80mm and a radius curvature of 5mm. The variables in the experiment were the length of the tubes built 50mm, 80mm and 120mm. Meanwhile, the thickness of the walls, consisting of laminates of silk/epoxy of 12, 24 and 30 plies, correspond to equivalent wall thickness of 1.7mm, 3.4mm and 4.2mm, respectively. The parameters measured were the total absorbed energy (Etotal), and the crash force efficiency (CFE). Etotal is the measure of the amount of energy that the structure can withstand without failure and thus is a measure of its strength, while CFE gives a quantitative indication of the mode of failure of the composites. The mode of failure was observed using photography.This research concentrates on the evaluation of crashworthiness characteristics of natural silk/epoxy composite square tubes energy-absorbers. Composite laminate specimens were subjected to static axial compression load and experimental evaluation of the energy absorption capability of silk/epoxy composite. Specimens were in the form of square cross-sections with the dimension of 80mm×80mm and a radius curvature of 5mm. The variables in the experiment were the length of the tubes built 50mm, 80mm and 120mm. Meanwhile, the thickness of the walls, consisting of laminates of silk/epoxy of 12, 24 and 30 plies, correspond to equivalent wall thickness of 1.7mm, 3.4mm and 4.2mm, respectively. The parameters measured were the total absorbed energy (Etotal), and the crash force efficiency (CFE). Etotal is the measure of the amount of energy that the structure can withstand without failure and thus is a measure of its strength, while CFE gives a quantitative indication of the mode of failure of the composites. The mode of failure was observed using photography.


Application of nanoparticle tracking analysis platform for the measurement of soot-in-oil agglomerates from automotive engines
Nanoparticle Tracking Analysis (NTA) has been applied to characterising soot agglomerates of particles and compared with Transmission Electron Microscoscopy (TEM). Soot nanoparticles were extracted from used oil drawn from the sump of a light duty automotive diesel engine. The samples were prepared for analysis by diluting with heptane. Individual tracking of soot agglomerates allows for size distribution analysis. The size of soot was compared with length measurements of projected two-dimensional TEM images of agglomerates. Both the techniques show that soot-in-oil exists as agglomerates with average size of 120nm. NTA is able to measure particles in polydisperse solutions and reports the size and volume distribution of soot-in-oil aggregates; it has the advantages of being fast and relatively low cost if compared with TEM.Nanoparticle Tracking Analysis (NTA) has been applied to characterising soot agglomerates of particles and compared with Transmission Electron Microscoscopy (TEM). Soot nanoparticles were extracted from used oil drawn from the sump of a light duty automotive diesel engine. The samples were prepared for analysis by diluting with heptane. Individual tracking of soot agglomerates allows for size distribution analysis. The size of soot was compared with length measurements of projected two-dimensional TEM images of agglomerates. Both the techniques show that soot-in-oil exists as agglomerates with average size of 120nm. NTA is able to measure particles in polydisperse solutions and reports the size and volume distribution of soot-in-oil aggregates; it has the advantages of being fast and relatively low cost if compared with TEM.


Tribological behavior of RH ceramics made from rice husk sliding against stainless steel, alumina, silicon carbide, and silicon nitride
The tribological behavior of rice husk (RH) ceramics, a hard, porous carbon material made from rice husk, sliding against stainless steel, alumina, silicon carbide, and silicon nitride (Si3N4) under dry conditions was investigated. High hardness of RH ceramics was obtained from the polymorphic crystallinity of silica. The friction coefficients for RH ceramics disks sliding against Si3N4 balls were extremely low (<0.1), irrespective of contact pressure or sliding velocity. Transfer films from RH ceramics formed on Si3N4 balls. Wear-mode maps indicated that the wear modes were powder formation under all tested conditions, resulting in low specific wear rates (<5×10−9mm2/N).The tribological behavior of rice husk (RH) ceramics, a hard, porous carbon material made from rice husk, sliding against stainless steel, alumina, silicon carbide, and silicon nitride (Si3N4) under dry conditions was investigated. High hardness of RH ceramics was obtained from the polymorphic crystallinity of silica. The friction coefficients for RH ceramics disks sliding against Si3N4 balls were extremely low (<0.1), irrespective of contact pressure or sliding velocity. Transfer films from RH ceramics formed on Si3N4 balls. Wear-mode maps indicated that the wear modes were powder formation under all tested conditions, resulting in low specific wear rates (<5×10−9mm2/N).


The influence of surface hardness on the fretting wear of steel pairs—Its role in debris retention in the contact
The influence of specimen hardness (between 275kgfmm−2 and 835kgfmm−2) in an AISI Type O1 steel-on-steel fretting contact was examined. In equal-hardness pairs, a variation in the wear volume of around 20% across the range of hardnesses examined was observed. However, in pairs where the two specimens in the couple had different hardnesses, a critical hardness differential threshold existed, above which the wear was predominantly associated with the harder specimen (with debris embedment on the softer specimen surface). This retention of debris provides protection of that surface from further wear and also results in accelerated wear of the harder counterface due to abrasion by the oxide debris bed which has built up on the opposing specimen.The influence of specimen hardness (between 275kgfmm−2 and 835kgfmm−2) in an AISI Type O1 steel-on-steel fretting contact was examined. In equal-hardness pairs, a variation in the wear volume of around 20% across the range of hardnesses examined was observed. However, in pairs where the two specimens in the couple had different hardnesses, a critical hardness differential threshold existed, above which the wear was predominantly associated with the harder specimen (with debris embedment on the softer specimen surface). This retention of debris provides protection of that surface from further wear and also results in accelerated wear of the harder counterface due to abrasion by the oxide debris bed which has built up on the opposing specimen.


Theory of free electron vortices
Highlights► Theory of vortex electrons. ► Proof that free electrons can carry quantized orbital momentum. ► Proof that electron vortices are stable and robust under spherical aberration. ► Demonstration of the strong influence of partial coherence.


Precise and unbiased estimation of astigmatism and defocus in transmission electron microscopy
Highlights► Unbiased and precise defocus and astigmatism estimation with related uncertainties. ► The background in the PSD is suppressed by adaptive filtering. ► Robust template matching in polar representation detects also very low astigmatism. ► Outlier rejection of detected rings based on equidistance of CTF zeros in q2-space. ► Thon ring averaging (with Cs influence) can enhance the SNR of the rings in 1D PSD.


Computer vision, archaeological classification and China's terracotta warriors
Structure-from-motion and multiview-stereo together offer a computer vision technique for reconstructing detailed 3D models from overlapping images of anything from large landscapes to microscopic features. Because such models can be generated from ordinary photographs taken with standard cameras in ordinary lighting conditions, these techniques are revolutionising digital recording and analysis in archaeology and related subjects such as palaeontology, museum studies and art history. However, most published treatments so far have focused merely on this technique's ability to produce low-cost, high quality representations, with one or two also suggesting new opportunities for citizen science. However, perhaps the major artefact scale advantage comes from significantly enhanced possibilities for 3D morphometric analysis and comparative taxonomy. We wish to stimulate further discussion of this new research domain by considering a case study using a famous and contentious set of archaeological objects: the terracotta warriors of China's first emperor.Structure-from-motion and multiview-stereo together offer a computer vision technique for reconstructing detailed 3D models from overlapping images of anything from large landscapes to microscopic features. Because such models can be generated from ordinary photographs taken with standard cameras in ordinary lighting conditions, these techniques are revolutionising digital recording and analysis in archaeology and related subjects such as palaeontology, museum studies and art history. However, most published treatments so far have focused merely on this technique's ability to produce low-cost, high quality representations, with one or two also suggesting new opportunities for citizen science. However, perhaps the major artefact scale advantage comes from significantly enhanced possibilities for 3D morphometric analysis and comparative taxonomy. We wish to stimulate further discussion of this new research domain by considering a case study using a famous and contentious set of archaeological objects: the terracotta warriors of China's first emperor.


Cosmology with self-adjusting vacuum energy density from a renormalization group fixed point
Cosmologies with a time dependent Newton constant and cosmological constant are investigated. The scale dependence of G and Λ is governed by a set of renormalization group equations which is coupled to Einstein's equation in a consistent way. The existence of an infrared attractive renormalization group fixed point is postulated, and the cosmological implications of this assumption are explored. It turns out that in the late Universe the vacuum energy density is automatically adjusted so as to equal precisely the matter energy density, and that the deceleration parameter approaches q=−1/4. This scenario might explain the data from recent observations of high redshift type Ia supernovae and the cosmic microwave background radiation without introducing a quintessence field.Cosmologies with a time dependent Newton constant and cosmological constant are investigated. The scale dependence of G and Λ is governed by a set of renormalization group equations which is coupled to Einstein's equation in a consistent way. The existence of an infrared attractive renormalization group fixed point is postulated, and the cosmological implications of this assumption are explored. It turns out that in the late Universe the vacuum energy density is automatically adjusted so as to equal precisely the matter energy density, and that the deceleration parameter approaches q=−1/4. This scenario might explain the data from recent observations of high redshift type Ia supernovae and the cosmic microwave background radiation without introducing a quintessence field.
[1] S. Perlmutter Astrophys. J. 517 1999 565 [2] A. Riess Astron. J. 117 1999 707 [3] For a review, see A. Riess astro-ph/0005229 [4] P. de Barnardis Nature 404 2000 955 A.E. Lange astro-ph/0005004 [5] S. Hanany astro-ph/0005123 [6] S. Weinberg Rev. Mod. Phys. 61 1989 1 astro-ph/9610044 [7] V. Sahni A. Starobinsky astro-ph/9904398 N. Straumann astro-ph/9908342 [8] I. Zlatev L. Wang P.J. Steinhardt Phys. Rev. Lett. 82 1998 896 C. Armendariz-Picon V. Mukhanov P.J. Steinhardt Phys. Rev. Lett. 85 2000 4438 C. Armendariz-Picon V. Mukhanov P.J. Steinhardt Phys. Rev. D 63 2001 103510 P.J. Steinhardt L. Wang I. Zlatev Phys. Rev. D 59 1999 123504 P. Brax J. Martin A. Riazuelo Phys. Rev. D 62 2000 103505 [9] A. Hebecker C. Wetterich hep-ph/0003287 A. Hebecker C. Wetterich hep-ph/0008205 [10] M. Reuter C. Wetterich Phys. Lett. B 188 1987 38 [11] For a recent review, see R. Brandenberger hep-ph/9910410 [12] A. Bonanno M. Reuter hep-th/0106133 [13] M. Reuter Phys. Rev. D 57 1998 971 hep-th/9605030 For a brief introduction, see M. Reuter in: Annual Report 2000 of the International School in Physics and Mathematics, Tbilisi, Georgia hep-th/0012069 [14] A. Bonanno M. Reuter Phys. Rev. D 62 2000 043008 hep-th/0002196 [15] A. Bonanno M. Reuter Phys. Rev. D 60 1999 084011 gr-qc/9811026 [16] A. Beesham Nuovo Cimento 96B 1986 17 A. Beesham Int. J. Theor. Phys. 25 1986 1295 A.-M.M. Abdel-Rahman Gen. Rel. Grav. 22 1990 655 M.S. Berman Phys. Rev. D 43 1991 1075 M.S. Berman Gen. Rel. Grav. 23 1991 465 R.F. Sistero Gen. Rel. Grav. 23 1991 1265 T. Singh A. Beesham Gen. Rel. Grav. 32 2000 607 A. Arbab A. Beesham Gen. Rel. Grav. 32 2000 615 A. Arbab gr-qc/9909044 [17] D. Kalligas P. Wesson C.W.F. Everitt Gen. Rel. Grav. 24 1992 351 [18] For a recent review, see J. Berges N. Tetradis C. Wetterich hep-th/0005122 [19] N.C. Tsamis R.P. Woodard Phys. Lett. B 301 1993 351 N.C. Tsamis R.P. Woodard Ann. Phys. (N.Y.) 238 1995 1 N.C. Tsamis R.P. Woodard Nucl. Phys. B 474 1996 235 I. Antoniadis E. Mottola Phys. Rev. D 45 1992 2013 [20] C. Wetterich Gen. Rel. Grav. 30 1998 159 [21] M. Carfora K. Piotrkowska Phys. Rev. D 53 1995 4393 and references therein [22] V. Mukhanov L.R.W. Abramo R. Brandenberger Phys. Rev. Lett. 78 1997 1624 L.R.W. Abramo R. Brandenberger V. Mukhanov Phys. Rev. D 56 1997 3248 R. Brandenberger hep-th/0004016 W. Unruh astro-ph/9802323 [23] W. Souma Prog. Theor. Phys. 102 1999 181 [24] O. Lauscher M. Reuter hep-th/0108049 and in preparation [25] M. Reuter, F. Saueressig, in preparation [26] M. Reuter C. Wetterich Nucl. Phys. B 506 1997 483 A. Chamseddine M. Reuter Nucl. Phys. B 317 1989 757 [27] H. Bondi J. Samuel gr-qc/9607009 For a comprehensive account, see J. Barbour H. Pfister Mach's Principle 1995 Birkhäuser Boston [28] G.T. Gillies Rep. Prog. Phys. 60 1997 151 [29] O. Bertolami P.J. Martins gr-qc/9910056 O. Bertolami J. Mourao J. Perez-Mercader Phys. Lett. B 311 1993 27 O. Bertolami J. Garcia-Bellido Int. J. Mod. Phys. D 5 1996 363

Analysis of the first RHIC results in the string fusion model
First results from RHIC on charged multiplicities, evolution of multiplicities with centrality, particle ratios and transverse momentum distributions in central and minimum bias collisions, are analyzed in a string model which includes hard collisions, collectivity in the initial state considered as string fusion, and rescattering of the produced secondaries. Multiplicities and their evolution with centrality are successfully reproduced. Transverse momentum distributions in the model show a larger pT-tail than experimental data, disagreement which grows with increasing centrality. Discrepancies with particle ratios appear and are examined comparing with previous features of the model at SPS.First results from RHIC on charged multiplicities, evolution of multiplicities with centrality, particle ratios and transverse momentum distributions in central and minimum bias collisions, are analyzed in a string model which includes hard collisions, collectivity in the initial state considered as string fusion, and rescattering of the produced secondaries. Multiplicities and their evolution with centrality are successfully reproduced. Transverse momentum distributions in the model show a larger pT-tail than experimental data, disagreement which grows with increasing centrality. Discrepancies with particle ratios appear and are examined comparing with previous features of the model at SPS.


AdS3 OM theory and the self-dual string or membranes ending on the five-brane
We describe properties of the M-theory five-brane containing Q coincident self-dual strings on its worldvolume. This is the five-brane description of Q membranes ending on the five-brane. In particular, we consider a Maldacena-like low energy limit in the six-dimensional worldvolume which yields a near ‘horizon’ description of the self-dual string using light open membranes, i.e., OM theory, in an AdS3×S3 geometry.We describe properties of the M-theory five-brane containing Q coincident self-dual strings on its worldvolume. This is the five-brane description of Q membranes ending on the five-brane. In particular, we consider a Maldacena-like low energy limit in the six-dimensional worldvolume which yields a near ‘horizon’ description of the self-dual string using light open membranes, i.e., OM theory, in an AdS3×S3 geometry.
[1] E. Bergshoeff M. de Roo T. Ortı́n Phys. Lett. B 386 1996 85 hep-th/9606118 E. Witten J. Geom. Phys. 22 1997 103 hep-th/9610234 M. Aganagic J. Park C. Popescu J.H. Schwarz Nucl. Phys. B 496 1997 191 hep-th/9701166 E. Sezgin P. Sundell hep-th/9902171 Proceedings of the Trieste Conference on Superfivebranes and Physics in 5+1 Dimensions, 1–3 April, 1998, Trieste, Italy [2] N. Seiberg Nucl. Phys. Proc. Suppl. 67 1998 158 hep-th/9705117 O. Aharony M. Berkooz S. Kachru N. Seiberg E. Silverstein Adv. Theor. Math. Phys. 1 1998 148 hep-th/9707079 O. Aharony M. Berkooz N. Seiberg Adv. Theor. Math. Phys. 2 1998 119 hep-th/9712117 R. Dijkgraaf E. Verlinde H. Verlinde Nucl. Phys. B 486 1997 89 hep-th/9604055 M. Henningson Phys. Rev. Lett. 85 2000 5280 hep-th/0006231 [3] P.S. Howe E. Sezgin Phys. Lett. B 394 1997 62 hep-th/9611008 P.S. Howe E. Sezgin P.C. West Phys. Lett. B 399 1997 49 hep-th/9702008 A. Nurmagambetov P. Pasti D. Sorokin M. Tonin Phys. Rev. Lett. 78 1997 4332 hep-th/9701149 M. Cederwall B.E.W. Nilsson P. Sundell JHEP 9804 1998 007 hep-th/9712059 [4] A. Strominger Phys. Lett. B 383 1996 44 hep-th/9512059 P.K. Townsend Phys. Lett. B 373 1996 68 hep-th/9512062 [5] C.S. Chu E. Sezgin JHEP 9712 1997 001 hep-th/9710223 [6] P.S. Howe N.D. Lambert P.C. West Nucl. Phys. B 515 1998 203 hep-th/9709014 [7] G.W. Gibbons Nucl. Phys. B 514 1998 603 hep-th/9709027 [8] R. Gopakumar S. Minwalla N. Seiberg A. Strominger JHEP 0008 2000 008 hep-th/0006062 T. Harmark Nucl. Phys. B 593 2001 76 hep-th/0007147 [9] E. Bergshoeff D.S. Berman J.P. van der Schaar P. Sundell Phys. Lett. B 492 2000 193 hep-th/0006112 [10] D.S. Berman P. Sundell JHEP 0010 2000 014 hep-th/0007052 [11] R. Gopakumar J. Maldacena S. Minwalla A. Strominger JHEP 0006 2000 036 hep-th/0005048 N. Seiberg L. Susskind N. Toumbas JHEP 0006 2000 021 hep-th/0005040 [12] J.X. Lu hep-th/0102056 H. Larsson P. Sundell hep-th/0103188 [13] N.R. Constable R.C. Myers O. Tafjord hep-th/0105035 N.R. Constable R.C. Myers O. Tafjord hep-th/0102080 N.R. Constable R.C. Myers O. Tafjord Phys. Rev. D 61 2000 106009 hep-th/9911136 [14] A. Karch L. Randall hep-th/0105132 A. Karch L. Randall hep-th/0105108 [15] J. Maldacena Adv. Theor. Math. Phys. 2 1998 231 J. Maldacena Int. J. Theor. Phys. 38 1998 1113 hep-th/9711200 O. Aharony S.S. Gubser J. Maldacena H. Ooguri Y. Oz Phys. Rep. 323 2000 183 hep-th/9905111 [16] E. Bergshoeff D.S. Berman J.P. van der Schaar P. Sundell Nucl. Phys. B 590 2000 173 hep-th/0005026 [17] D.S. Berman M. Cederwall U. Gran H. Larsson B.E.W. Nilsson P. Sundell hep-th/0109107 [18] D.S. Berman V.L. Campos M. Cederwall U. Gran H. Larsson B.E.W. Nilsson P. Sundell JHEP 0105 2001 002 [19] J.P. van der Schaar JHEP 0108 2001 048 J.P. van der Schaar E. Bergshoeff hep-th/011061 [20] G.W. Gibbons P.C. West hep-th/0011149 [21] C.G. Callan J.M. Maldacena Nucl. Phys. B 513 1998 198 hep-th/9708147 [22] S. Lee A. Peet L. Thorlacius Nucl. Phys. B 514 1998 161 hep-th/9710097 D. Bak J. Lee H. Min Phys. Rev. D 59 1999 045011 hep-th/9806149 K.G. Savvidy G.K. Savvidy Nucl. Phys. B 561 1999 117 hep-th/9902023 [23] D. Kastor J. Traschen Phys. Rev. D 61 2000 024034 hep-th/9906237 [24] I.R. Klebanov Nucl. Phys. B 496 1997 231 hep-th/9702076 [25] P.S. Howe E. Sezgin Phys. Lett. B 390 1997 133 hep-th/9607227 [26] V.L. Campos G. Ferretti P. Salomonson JHEP 0012 2000 011 hep-th/0011271 [27] E.S. Fradkin V.Ya. Linetsky Phys. Lett. B 261 1991 26 [28] J.L. Barbon E. Rabinovici hep-th/0104169 [29] A. Giveon D. Kutasov N. Seiberg Adv. Theor. Math. Phys. 2 1998 733 hep-th/9806194

Description of supernova data in conformal cosmology without cosmological constant
We consider cosmological consequences of a conformal-invariant formulation of Einstein's General Relativity where instead of the scale factor of the spatial metrics in the action functional a massless scalar (dilaton) field occurs which scales all masses including the Planck mass. Instead of the expansion of the universe we obtain the Hoyle–Narlikar type of mass evolution, where the temperature history of the universe is replaced by the mass history. We show that this conformal-invariant cosmological model gives a satisfactory description of the new supernova Ia data for the effective magnitude–redshift relation without a cosmological constant and make a prediction for the high-redshift behavior which deviates from that of standard cosmology for z>1.7.We consider cosmological consequences of a conformal-invariant formulation of Einstein's General Relativity where instead of the scale factor of the spatial metrics in the action functional a massless scalar (dilaton) field occurs which scales all masses including the Planck mass. Instead of the expansion of the universe we obtain the Hoyle–Narlikar type of mass evolution, where the temperature history of the universe is replaced by the mass history. We show that this conformal-invariant cosmological model gives a satisfactory description of the new supernova Ia data for the effective magnitude–redshift relation without a cosmological constant and make a prediction for the high-redshift behavior which deviates from that of standard cosmology for z>1.7.


Statistical coalescence model analysis of J/ψ production in Pb+Pb collisions at 158 AGeV
Production of J/ψ mesons in heavy ion collisions is considered within the statistical coalescence model. The model is in agreement with the experimental data of the NA50 Collaboration for Pb+Pb collisions at 158 AGeV in a wide centrality range, including the so-called “anomalous” suppression domain. The model description of the J/ψ data requires, however, strong enhancement of the open charm production in central Pb+Pb collisions. This model prediction may be checked in the future SPS runs.Production of J/ψ mesons in heavy ion collisions is considered within the statistical coalescence model. The model is in agreement with the experimental data of the NA50 Collaboration for Pb+Pb collisions at 158 AGeV in a wide centrality range, including the so-called “anomalous” suppression domain. The model description of the J/ψ data requires, however, strong enhancement of the open charm production in central Pb+Pb collisions. This model prediction may be checked in the future SPS runs.


The handbag contribution to γγ→ππ and KK
We investigate the soft handbag contribution to two-photon annihilation into pion or kaon pairs at large energy and momentum transfer. The amplitude is expressed as a hard γγ→qq̄ subprocess times a form factor describing the soft transition from qq̄ to the meson pair. We find the calculated angular dependence of the cross section in good agreement with data, and extract annihilation form factors of plausible size. A key prediction of the handbag mechanism is that the differential cross section is the same for charged and neutral pion pairs, in striking contrast with what is found in the hard scattering approach.We investigate the soft handbag contribution to two-photon annihilation into pion or kaon pairs at large energy and momentum transfer. The amplitude is expressed as a hard γγ→qq̄ subprocess times a form factor describing the soft transition from qq̄ to the meson pair. We find the calculated angular dependence of the cross section in good agreement with data, and extract annihilation form factors of plausible size. A key prediction of the handbag mechanism is that the differential cross section is the same for charged and neutral pion pairs, in striking contrast with what is found in the hard scattering approach.


Higgs decays in the two Higgs doublet model: large quantum effects in the decoupling regime
We study the Higgs-boson decays h0→bb̄, h0→γγ and h0→γZ within the framework of the two Higgs doublet model (THDM) in the context of the decoupling regime, together with tree level unitarity constraints. We show that when the light CP-even Higgs boson of the THDM mimics the Standard Model Higgs boson, not only the one-loop effects to h0→{γγ,γZ} but also the one-loop contribution to h0→bb̄ can be used to distinguish between THDM and SM. The size of the quantum effects in h0→bb̄ are of the same order as in h0→{γγ,γZ} and can reach 25% in both cases.We study the Higgs-boson decays h0→bb̄, h0→γγ and h0→γZ within the framework of the two Higgs doublet model (THDM) in the context of the decoupling regime, together with tree level unitarity constraints. We show that when the light CP-even Higgs boson of the THDM mimics the Standard Model Higgs boson, not only the one-loop effects to h0→{γγ,γZ} but also the one-loop contribution to h0→bb̄ can be used to distinguish between THDM and SM. The size of the quantum effects in h0→bb̄ are of the same order as in h0→{γγ,γZ} and can reach 25% in both cases.


Positive parity pentaquarks pragmatically predicted
We consider the possibility that the lightest pentaquark is a parity-even state, with one unit of orbital angular momentum. Working within the framework of a constituent quark model, we show that dominant spin-flavor interactions render certain parity-even states lighter than any pentaquark with all quarks in the spatial ground state. For such states, we focus on predicting the mass and decays of other members of the same SU(3) flavor multiplet. Specifically, we consider the strangeness −2 cascade pentaquarks, which are relatively immune to mixing. We take into account flavor SU(3) breaking effects originating from the strange quark mass as well as from the structure of the spin-flavor exchange interactions themselves. We predict the lightest cascade pentaquarks at approximately 1906 MeV, with a full width ∼3 times larger than that of the Θ+.We consider the possibility that the lightest pentaquark is a parity-even state, with one unit of orbital angular momentum. Working within the framework of a constituent quark model, we show that dominant spin-flavor interactions render certain parity-even states lighter than any pentaquark with all quarks in the spatial ground state. For such states, we focus on predicting the mass and decays of other members of the same SU(3) flavor multiplet. Specifically, we consider the strangeness −2 cascade pentaquarks, which are relatively immune to mixing. We take into account flavor SU(3) breaking effects originating from the strange quark mass as well as from the structure of the spin-flavor exchange interactions themselves. We predict the lightest cascade pentaquarks at approximately 1906 MeV, with a full width ∼3 times larger than that of the Θ+.


Helium clustering in neutron-rich Be isotopes
Measurements of the helium-cluster breakup and neutron removal cross-sections for neutron-rich Be isotopes 10–12,14Be are presented. These have been studied in the 30 to 42 MeV/nucleon energy range where reaction measurements are proposed to be sensitive to the cluster content of the ground-state wave-function. These measurements provide a comprehensive survey of the decay processes of the Be isotopes by which the valence neutrons are removed revealing the underlying α–α core-cluster structure. The measurements indicate that clustering in the Be isotopes remains important up to the drip-line nucleus 14Be and that the dominant helium-cluster structure in the neutron-rich Be isotopes corresponds to α–Xn–α.Measurements of the helium-cluster breakup and neutron removal cross-sections for neutron-rich Be isotopes 10–12,14Be are presented. These have been studied in the 30 to 42 MeV/nucleon energy range where reaction measurements are proposed to be sensitive to the cluster content of the ground-state wave-function. These measurements provide a comprehensive survey of the decay processes of the Be isotopes by which the valence neutrons are removed revealing the underlying α–α core-cluster structure. The measurements indicate that clustering in the Be isotopes remains important up to the drip-line nucleus 14Be and that the dominant helium-cluster structure in the neutron-rich Be isotopes corresponds to α–Xn–α.


Prospects for detecting a neutrino magnetic moment with a tritium source and beta-beams
We compare the prospects for detecting a neutrino magnetic moment by the measurement of neutrinos from a tritium source, reactors and low-energy beta-beams. In all cases the neutrinos or antineutrinos are detected by scattering of electrons. We find that a large (20 MCurie) tritium source could improve the limit on the neutrino magnetic moment significantly, down to the level of a few ×10−12 in units of Bohr magnetons μB while low-energy beta-beams with sufficiently rapid production of ions could improve the limits to the level of a few ×10−11μB. The latter would require ion production at the rate of at least 1015 s−1.We compare the prospects for detecting a neutrino magnetic moment by the measurement of neutrinos from a tritium source, reactors and low-energy beta-beams. In all cases the neutrinos or antineutrinos are detected by scattering of electrons. We find that a large (20 MCurie) tritium source could improve the limit on the neutrino magnetic moment significantly, down to the level of a few ×10−12 in units of Bohr magnetons μB while low-energy beta-beams with sufficiently rapid production of ions could improve the limits to the level of a few ×10−11μB. The latter would require ion production at the rate of at least 1015 s−1.


Measurements of primary and atmospheric cosmic-ray spectra with the BESS-TeV spectrometer
Primary and atmospheric cosmic-ray spectra were precisely measured with the BESS-TeV spectrometer. The spectrometer was upgraded from BESS-98 to achieve seven times higher resolution in momentum measurement. We report absolute fluxes of primary protons and helium nuclei in the energy ranges, 1–540 GeV and 1–250 GeV/n, respectively, and absolute flux of atmospheric muons in the momentum range 0.6–400 GeV/c.Primary and atmospheric cosmic-ray spectra were precisely measured with the BESS-TeV spectrometer. The spectrometer was upgraded from BESS-98 to achieve seven times higher resolution in momentum measurement. We report absolute fluxes of primary protons and helium nuclei in the energy ranges, 1–540 GeV and 1–250 GeV/n, respectively, and absolute flux of atmospheric muons in the momentum range 0.6–400 GeV/c.


Generalized Calogero model in arbitrary dimensions
We define a new multispecies model of Calogero type in D dimensions with harmonic, two-body and three-body interactions. Using the underlying conformal SU(1,1) algebra, we indicate how to find the complete set of the states in Bargmann–Fock space. There are towers of states, with equidistant energy spectra in each tower. We explicitely construct all polynomial eigenstates, namely the center-of-mass states and global dilatation modes, and find their corresponding eigenenergies. We also construct ladder operators for these global collective states. Analysing corresponding Fock space, we detect the universal critical point at which the model exhibits singular behavior. The above results are universal for all systems with underlying conformal SU(1,1) symmetry.We define a new multispecies model of Calogero type in D dimensions with harmonic, two-body and three-body interactions. Using the underlying conformal SU(1,1) algebra, we indicate how to find the complete set of the states in Bargmann–Fock space. There are towers of states, with equidistant energy spectra in each tower. We explicitely construct all polynomial eigenstates, namely the center-of-mass states and global dilatation modes, and find their corresponding eigenenergies. We also construct ladder operators for these global collective states. Analysing corresponding Fock space, we detect the universal critical point at which the model exhibits singular behavior. The above results are universal for all systems with underlying conformal SU(1,1) symmetry.
[1] F. Calogero J. Math. Phys. 10 1969 2191 F. Calogero J. Math. Phys. 10 1969 2197 F. Calogero J. Math. Phys. 12 1971 419 [2] See, e.g. J.F. Van Dijen L. Vinet Calogero–Moser–Sutherland Models CRM Series in Mathematical Physics vol. 25 2000 Springer Berlin [3] B.D. Simmons P.A. Lee B.L. Altshuler Phys. Rev. Lett. 72 1994 64 L. Lapointe L. Vinet Commun. Math. Phys. 178 1996 425 [4] N. Kawakami S.K. Yang Phys. Rev. Lett. 67 1991 2493 N.F. Johnson L. Quiroga Phys. Rev. Lett. 74 1995 4277 N.F. Johnson L. Quiroga J. Phys. Condens. Matter 9 1997 5889 G.W. Gibbons P.K. Townsend Phys. Lett. B 454 1999 187 D. Birmingham K.S. Gupta S. Sen Phys. Lett. B 505 2001 191 [5] F.D.M. Haldane Phys. Rev. Lett. 67 1991 937 Y.S. Wu Phys. Rev. Lett. 73 1994 922 M.V.N. Murthy R. Shankar Phys. Rev. Lett. 73 1994 3331 S. Mashkevich Phys. Lett. A 233 1997 30 [6] P. Forrester J. Phys. A: Math. Gen. 25 1992 L607 C. Furtlehner S. Ouvry Mod. Phys. Lett. B 9 1995 503 D. Sen Nucl. Phys. B 479 1996 554 A. Dasniers de Veigy Nucl. Phys. B 483 1997 580 [7] S. Meljanac M. Mileković A. Samsarov Phys. Lett. B 573 2003 202 [8] G. Date P.K. Ghosh M.V.N. Murthy Phys. Rev. Lett. 81 1998 3051 M.V.N. Murthy R.K. Bhaduri D. Sen Phys. Rev. Lett. 76 1996 4103 A. Khare K. Ray Phys. Lett. A 230 1997 139 R.K. Ghosh S. Rao Phys. Lett. A 238 1998 213 P.K. Ghosh Phys. Lett. A 229 1997 203 P.K. Ghosh J. Phys. A: Math. Gen. 34 2001 5583 [9] N. Gurappa P.K. Panigrahi Phys. Rev. B 59 1999 R2490 N. Gurappa P.K. Panigrahi Phys. Rev. B 67 2003 155323 [10] V. Bardek L. Jonke S. Meljanac M. Mileković Phys. Lett. B 531 2002 311 [11] F. Calogero C. Marchioro J. Math. Phys. 14 1973 182 [12] C.L. Kane S. Kivelson D.H. Lee S.C. Zhang Phys. Rev. B 43 1991 3255 [13] M. Vasiliev Int. J. Mod. Phys. A 6 1991 1115 A.P. Polychronakos Phys. Rev. Lett. 69 1992 703 L. Brink T.H. Hansson M. Vasiliev Phys. Lett. B 286 1992 109 L. Brink T.H. Hansson S.E. Konstein M. Vasiliev Nucl. Phys. B 384 1993 591 N. Gurappa P.K. Panigrahi V. Srinivasan Mod. Phys. Lett. A 13 1998 339 S. Meljanac M. Mileković M. Stojić Eur. Phys. J. C 60 2002 331 [14] A.M. Perelomov Generalized Coherent States and Their Applications 1986 Springer Berlin

Solar neutrinos as probes of neutrino–matter interactions
Data from solar neutrino and KamLAND experiments have led to a discovery of nonzero neutrino masses. Here we investigate what these data can tell us about neutrino interactions with matter, including the poorly constrained flavor-changing νe–ντ interactions. We give examples of the interaction parameters that are excluded by the solar/KamLAND data and are beyond the reach of other experiments. We also demonstrate that flavor-changing interactions, at the allowed level, may profoundly modify the conversion probability for neutrinos of energy ≲6 MeV and the values of the mass parameter inferred from the data. The implications for future experiments are discussed.Data from solar neutrino and KamLAND experiments have led to a discovery of nonzero neutrino masses. Here we investigate what these data can tell us about neutrino interactions with matter, including the poorly constrained flavor-changing νe–ντ interactions. We give examples of the interaction parameters that are excluded by the solar/KamLAND data and are beyond the reach of other experiments. We also demonstrate that flavor-changing interactions, at the allowed level, may profoundly modify the conversion probability for neutrinos of energy ≲6 MeV and the values of the mass parameter inferred from the data. The implications for future experiments are discussed.


Low-energy ππ photoproduction off nuclei
In the present Letter we investigate π0π0 and π±π0 photoproduction off complex nuclei at incident beam energies of 400–460 MeV. Simulations of two pion photoproduction on protons and nuclei are performed by means of a semi-classical BUU transport model including a full coupled-channel treatment of the final state interactions. Elastic scattering of the final state pions with the nucleons in the surrounding nuclear medium is found to yield a downward shift of the ππ invariant mass distribution. We show that the target mass dependence of the π0π0 invariant mass spectrum as measured by the TAPS Collaboration can be explained without introducing medium effects beyond absorption and quasi-elastic scattering of the final state particles. On the other hand, we find considerable discrepancies with the data in the π±π0 channel, which are not understood.In the present Letter we investigate π0π0 and π±π0 photoproduction off complex nuclei at incident beam energies of 400–460 MeV. Simulations of two pion photoproduction on protons and nuclei are performed by means of a semi-classical BUU transport model including a full coupled-channel treatment of the final state interactions. Elastic scattering of the final state pions with the nucleons in the surrounding nuclear medium is found to yield a downward shift of the ππ invariant mass distribution. We show that the target mass dependence of the π0π0 invariant mass spectrum as measured by the TAPS Collaboration can be explained without introducing medium effects beyond absorption and quasi-elastic scattering of the final state particles. On the other hand, we find considerable discrepancies with the data in the π±π0 channel, which are not understood.


“Coulomb + linear” form of the static QCD potential in operator–product expansion
The static QCD potential is analyzed in operator-product expansion within potential-NRQCD framework when r≪ΛQCD−1. We show that the leading short-distance contribution to the potential, defined as a perturbatively computable Wilson coefficient, can be expressed, up to O(r2), as a “Coulomb + linear” potential. It coincides with the “Coulomb + linear” potential obtained previously from renormalon-dominance hypothesis. Non-perturbative contributions are O(r2) and subleading.The static QCD potential is analyzed in operator-product expansion within potential-NRQCD framework when r≪ΛQCD−1. We show that the leading short-distance contribution to the potential, defined as a perturbatively computable Wilson coefficient, can be expressed, up to O(r2), as a “Coulomb + linear” potential. It coincides with the “Coulomb + linear” potential obtained previously from renormalon-dominance hypothesis. Non-perturbative contributions are O(r2) and subleading.


Exact propagators in harmonic superspace
Within the background field formulation in harmonic superspace for quantum N=2 super-Yang–Mills theories, the propagators of the matter, gauge and ghost superfields possess a complicated dependence on the SU(2) harmonic variables via the background vector multiplet. This dependence is shown to simplify drastically in the case of an on-shell vector multiplet. For a covariantly constant background vector multiplet, we exactly compute all the propagators. In conjunction with the covariant multi-loop scheme developed in hep-th/0302205, these results provide an efficient (manifestly N=2 supersymmetric) technical setup for computing multi-loop quantum corrections to effective actions in N=2 supersymmetric gauge theories, including the N=4 super-Yang–Mills theory.Within the background field formulation in harmonic superspace for quantum N=2 super-Yang–Mills theories, the propagators of the matter, gauge and ghost superfields possess a complicated dependence on the SU(2) harmonic variables via the background vector multiplet. This dependence is shown to simplify drastically in the case of an on-shell vector multiplet. For a covariantly constant background vector multiplet, we exactly compute all the propagators. In conjunction with the covariant multi-loop scheme developed in hep-th/0302205, these results provide an efficient (manifestly N=2 supersymmetric) technical setup for computing multi-loop quantum corrections to effective actions in N=2 supersymmetric gauge theories, including the N=4 super-Yang–Mills theory.
[1] I.L. Buchbinder E.I. Buchbinder S.M. Kuzenko B.A. Ovrut Phys. Lett. B 417 1998 61 hep-th/9704214 [2] I.L. Buchbinder S.M. Kuzenko B.A. Ovrut Phys. Lett. B 433 1998 335 hep-th/9710142 I.L. Buchbinder S.M. Kuzenko B.A. Ovrut Covariant harmonic supergraphity for  N = 2  super-Yang–Mills theories J. Wess E. Ivanov Supersymmetries and Quantum Symmetries 1999 Springer Berlin hep-th/9810040 [3] I.L. Buchbinder S.M. Kuzenko Mod. Phys. Lett. A 13 1998 1623 hep-th/9804168 [4] A. Galperin E. Ivanov S. Kalitsyn V. Ogievetsky E. Sokatchev Class. Quantum Grav. 1 1984 469 [5] A. Galperin E.A. Ivanov V. Ogievetsky E. Sokatchev Class. Quantum Grav. 2 1985 601 A. Galperin E.A. Ivanov V. Ogievetsky E. Sokatchev Class. Quantum Grav. 2 1985 617 [6] A.S. Galperin E.A. Ivanov V.I. Ogievetsky E.S. Sokatchev Harmonic Superspace 2001 Cambridge Univ. Press Cambridge [7] R. Grimm M. Sohnius J. Wess Nucl. Phys. B 133 1978 275 [8] S.M. Kuzenko I.N. McArthur JHEP 0310 2003 029 hep-th/0308136 [9] S.M. Kuzenko I.N. McArthur JHEP 0305 2003 015 hep-th/0302205 [10] T. Ohrndorf Phys. Lett. B 176 1986 421 [11] J.S. Schwinger Phys. Rev. 82 1951 664 [12] S.M. Kuzenko I.N. McArthur Phys. Lett. B 506 2001 140 hep-th/0101127 S.M. Kuzenko I.N. McArthur Phys. Lett. B 513 2001 213 hep-th/0105121 [13] G.V. Dunne hep-th/0406216 [14] I.L. Buchbinder S.M. Kuzenko A.A. Tseytlin Phys. Rev. D 62 2000 045001 hep-th/9911221 [15] G.V. Dunne C. Schubert Phys. Lett. B 526 2002 55 hep-th/0111134 [16] S.M. Kuzenko I.N. McArthur Phys. Lett. B 591 2004 304 hep-th/0403082 [17] J.M. Maldacena Adv. Theor. Math. Phys. 2 1998 231 hep-th/9711200 [18] I. Chepelev A.A. Tseytlin Nucl. Phys. B 515 1998 73 hep-th/9709087 A.A. Tseytlin Born–Infeld action, supersymmetry and string theory M. Shifman The Many Faces of the Superworld 2000 World Scientific Singapore 417 hep-th/9908105 [19] I.L. Buchbinder A.Y. Petrov A.A. Tseytlin Nucl. Phys. B 621 2002 179 hep-th/0110173 [20] S.M. Kuzenko I.N. McArthur hep-th/0403240 [21] N. Ohta H. Yamaguchi Phys. Rev. D 32 1985 1954

Preparation and characterization of core–shell battery materials for Li-ion batteries manufactured by substrate induced coagulation
In this work Substrate Induced Coagulation (SIC) was used to coat the cathode material LiCoO2, commonly used in Li-ion batteries, with fine nano-sized particulate titania. Substrate Induced Coagulation is a self-assembled dip-coating process capable of coating different surfaces with fine particulate materials from liquid media. A SIC coating consists of thin and rinse-prove layers of solid particles. An advantage of this dip-coating method is that the method is easy and cheap and that the materials can be handled by standard lab equipment. Here, the SIC coating of titania on LiCoO2 is followed by a solid-state reaction forming new inorganic layers and a core–shell material, while keeping the content of active battery material high. This titania based coating was designed to confine the reaction of extensively delithiated (charged) LiCoO2 and the electrolyte. The core–shell materials were characterized by SEM, XPS, XRD and Rietveld analysis.


Automatic sentence stress feedback for non-native English learners
This paper proposes a sentence stress feedback system in which sentence stress prediction, detection, and feedback provision models are combined. This system provides non-native learners with feedback on sentence stress errors so that they can improve their English rhythm and fluency in a self-study setting. The sentence stress feedback system was devised to predict and detect the sentence stress of any practice sentence. The accuracy of the prediction and detection models was 96.6% and 84.1%, respectively. The stress feedback provision model offers positive or negative stress feedback for each spoken word by comparing the probability of the predicted stress pattern with that of the detected stress pattern. In an experiment that evaluated the educational effect of the proposed system incorporated in our CALL system, significant improvements in accentedness and rhythm were seen with the students who trained with our system but not with those in the control group.


Pure shear stress reversal on a Cu-based bulk metallic glass reveals a Bauschinger-type effect
We have developed a torsion machine that can apply pure shear stress to small-diameter rod samples. We report preliminary results on Cu-based metallic glass samples held at constant torque in the elastic range. The inelastic angle of twist increases approximately linearly with the logarithm of time, interpreted as anelastic deformation. Reversal of torque reveals an effect analogous to the Bauschinger effect in polycrystalline metals. The relative deformation rate is increased by a factor of 4.5 on first reversal, an effect discussed in terms of the operation of shear transformation zones and related to structural change in the metallic glass.


Effect of grain size reduction of AA2124 aluminum alloy powder compacted by spark plasma sintering
Nanocrystalline (Average grain size ∼200nm) bulk AA2124 alloy was produced through high energy ball milling of microcrystalline powder followed by spark plasma sintering (SPS) at 480°C with a holding time of 10min. The effect of initial particle and grain size on the microstructural evolution as well as on the relative density and mechanical properties of the specimens consolidated through SPS and hot pressing (HP) at the same temperature for 60min was investigated for ball milled nano-powders (NP), as well as as-received micro-powders (MP). Results showed that the NP specimens consolidated with SPS had the highest microhardness values compared to the other specimens despite not achieving full densification. On the other hand, a general increase in density, hardness, and compressive strength was observed for all SPS consolidates compared to HP. The presence of aluminum oxide and its influence on the consolidation process as well as the resulting mechanical properties of the bulk specimens is also discussed.


A RESTful API for exchanging materials data in the AFLOWLIB.org consortium
The continued advancement of science depends on shared and reproducible data. In the field of computational materials science and rational materials design this entails the construction of large open databases of materials properties. To this end, an Application Program Interface (API) following REST principles is introduced for the AFLOWLIB.org materials data repositories consortium. AUIDs (Aflowlib Unique IDentifier) and AURLs (Aflowlib Uniform Resource Locator) are assigned to the database resources according to a well-defined protocol described herein, which enables the client to access, through appropriate queries, the desired data for post-processing. This introduces a new level of openness into the AFLOWLIB repository, allowing the community to construct high-level work-flows and tools exploiting its rich data set of calculated structural, thermodynamic, and electronic properties. Furthermore, federating these tools will open the door to collaborative investigations of unprecedented scope that will dramatically accelerate the advancement of computational materials design and development.


Discrete element modelling of flexible fibre packing
This paper presents Discrete Element Model simulations of packing of non-cohesive flexible fibres in a cylindrical vessel. No interstitial fluid effects are modelled. Each fibre-particle is modelled as a series of connected sphero-cylinders. In an initial study each particle is modelled a single rigid sphero-cylinder; the method has been used before but this study considers higher aspect ratios up to 30. This posed some modelling challenges in terms of stability which were overcome by imposing limits on the particle angular velocity. The results show very good agreement with experimental data in the literature and more detailed in-house experiments for packing volume fraction. Model results on particle orientation are also shown. The model is developed to include flexibility by connecting sphero-cylinders as sub-elements to describe a particle. Some basic tests are shown for the joint model that connects the sub-elements. The simulation results show similar trends to the rigid particle results with increased packing fraction. The effects of number of sub-elements, joint properties and contact friction are examined. The model has the potential for predicting packing of fibrous particles and fibre bundles relevant to the preparation of preforms for the production of discontinuously-reinforced polymer, ceramic and metallic matrix composites.


Realistic microstructure-based modelling of cyclic deformation and crack growth using crystal plasticity
Using crystal plasticity, finite element analyses were carried out to model cyclic deformation for a low solvus high refractory (LSHR) nickel superalloy at elevated temperature. The analyses were implemented using a representative volume element (RVE), consisting of realistic microstructure obtained from SEM images of the material. Monotonic, stress-relaxation and cyclic test data at 725°C were used to determine the model parameters from a fitting process and their sensitivity to RVE size and random grain orientation. In combination with extended finite element method (XFEM), the crystal plasticity model was further applied to predict surface crack growth, for which accumulated plastic strain was used as a fracture criterion. Again, realistic microstructure, taken from the cracking site on the surface of a plain fatigue specimen, was used to create the finite element model for crack growth analyses. The prediction was conducted for a pseudo-3D geometrical model, resembling the plane stress condition at specimen surface. The loading level at the cracking site was determined from a viscoplasticity finite element analysis of the fatigue specimen. The proposed model is capable of predicting the variation in growth rate in grains with different orientations.


Near electrical resonance signal enhancement (NERSE) in eddy-current crack detection
An investigation was performed into the effects of operating an absolute eddy-current testing (ECT) probe at frequencies close to its electrical resonance. A previously undocumented defect signal enhancement phenomenon, resulting from associated shifts in electrical resonant frequency, was observed and characterized. Experimental validation was performed on three notch defects on a typical aerospace superalloy, Titanium 6Al–4V. A conventional absolute ECT probe was operated by sweeping through a frequency range about the electrical resonance of the system (1−5MHz). The phenomenon results in signal-to-noise ratio (SNR) peak enhancements by a factor of up to 3.7, at frequencies approaching resonance, compared to those measured at 1MHz. The defect signal enhancement peaks are shown to be a result of resonant frequency shifts of the system due to the presence of defects within the material. A simple, operational approach for raising the sensitivity of conventional industrial eddy-current testing is proposed, based on the principles of the observed near electrical resonance signal enhancement (NERSE) phenomenon. The simple procedural change of operating within the NERSE frequency band does not require complex probe design, data analysis or, necessarily, identical coils. Therefore, it is a valuable technique for improving sensitivity, which complements other ECT methods.


Localisation of defects with time and frequency measurements using pulsed arrays
The frequency dependent directivity of the periodic permanent magnet transducer is used to extract information about the position of any discontinuities present in a sample. Two approaches are used: narrowband excitation and broadband pulsed generation. Simultaneous narrowband excitation, with the appropriate frequency, can be used to steer the ultrasound to a particular angle. Broadband excitation emits a wavefront that extends over a large range of angles, with the frequency of the wavefront varying smoothly as a function of angle. Using these two approaches, two-dimensional maps of any defects present in the sample can be obtained.


A probabilistic approach for the optimisation of ultrasonic array inspection techniques
Ultrasonic arrays are now used routinely for the inspection of engineering structures in order to maintain their integrity and assess their performance. Such inspections are usually optimised manually using empirical measurements and parametric studies which are laborious, time-consuming, and may not result in an optimal approach. In this paper, a general framework for the optimisation of ultrasonic array inspection techniques in NDE is presented. Defect detection rate is set as the main inspection objective and used to assess the performance of the optimisation framework. Statistical modelling of the inspection is used to form the optimisation problem and incorporate inspection uncertainty such as crack type and location, material properties and geometry, etc. A genetic algorithm is used to solve the global optimisation problem. As a demonstration, the optimisation framework is used with two objective functions based on array signal amplitude and signal-to-noise ratio (SNR). The optimal use of plane B-scan and total focusing method imaging algorithms is also investigated. The performance of the optimisation scheme is explored in simulation and then validated experimentally. It has been found that, for the inspection scenarios considered, TFM provides better detectability in a statistical sense than plane B-scan imaging in scenarios where uncertainty in the inspection is expected.


Accurate depth measurement of small surface-breaking cracks using an ultrasonic array post-processing technique
In this paper, the half-skip configuration of the Total Focusing Method (TFM) is used to image and size surface-breaking cracks. The TFM is an ultrasonic array post-processing technique which is used to synthetically focus at every image point in a target region. This paper considers the case of inspecting for cracks which have initiated from the far surface of a parallel-sided sample using an array on the near surface. Typically, only direct ray paths between the array and image points are included in the TFM algorithm and therefore the image obtained for this case consists only of root and tip indications; no specular reflection from the crack faces is captured. The tip indication often has such a poor signal-to-noise ratio that reliable crack depth measurement is challenging. With the Half-Skip TFM, instead of using directly-scattered signals, the image is formed using ultrasonic ray paths corresponding to the ultrasound that has reflected off the back surface and has then undergone specular reflection from the crack face back to the array. The technique is applied to experimental and simulated array data and is shown to measure the depth of small cracks (depth <1mm) with greater reliability than methods which rely on tip diffraction.


High temperature thickness measurements of stainless steel and low carbon steel using electromagnetic acoustic transducers
Thickness measurements were made on steel pipe at high temperatures using a non-contact watercooled EMAT (electromagnetic acoustic transducer) and also a laser-EMAT system where a portable Nd:YAG laser with a fibre optic cable was used to generate ultrasound on a sample, and a water-cooled coil-wound EMAT used to detect ultrasound. The set-up was designed so that the laser was fired through a hole in the centre of the EMAT, and a low pass 5MHz filter employed to reduce the plasma noise. Back wall reflections were clearly visible at temperatures up to 900°C on stainless and ferromagnetic low carbon steel, enabling wall thickness to be measured, taking into account thermal expansion of the sample. The water-cooled EMAT system can measure wall thickness on ferromagnetic low carbon steel at temperatures up to the Curie point; here, ultrasound generation is dependent on the magnetic state of the steel.


Weld defect detection using PPM EMAT generated shear horizontal ultrasound
Austenitic welds are inspected using PPM EMAT generated shear horizontal (SH) waves. Results are compared to measurements taken using a 1D piezoelectric phased array using the total focusing method (TFM). For the first time there is clear experimental evidence of the SH wave method demonstrating higher sensitivity to defect detection. SH waves suffer less beam steering in a weld than either compression or SV waves, which can miss defects due to weld microstructure anisotropy and attenuation. All defects were identified from every side of the weld/plate using the SH waves, but this was not possible using the piezoelectric transducer.


Exploring the third dimension: Volume electron microscopy comes of age
Groundbreaking advances in volume electron microscopy and specimen preparation are enabling the 3-dimensional visualisation of specimens with unprecedented detail, and driving a gratifying resurgence of interest in the ultrastructural examination of cellular systems. Serial section techniques, previously the domain of specialists, are becoming increasingly automated with the development of systems such as the automatic tape-collecting ultramicrotome, and serial blockface and focused ion beam scanning electron microscopes. These changes are rapidly broadening the scope of biomedical studies to which volume electron microscopy techniques can be applied beyond the brain. Further innovations in microscope design are also in the pipeline, which have the potential to enhance the speed and quality of data collection. The recent introduction of integrated light and electron microscopy systems will revolutionise correlative light and volume electron microscopy studies, by enabling the sequential collection of data from light and electron imaging modalities without intermediate specimen manipulation. In doing so, the acquisition of comprehensive functional information and direct correlation with ultrastructural details within a 3-dimensional reference space will become routine. The prospects for volume electron microscopy are therefore bright, and the stage is set for a challenging and exciting future.


Solvent effect on two-photon absorption and fluorescence of rhodamine dyes
For a series of rhodamine dyes, two-photon absorption (TPA) and two-photon fluorescence (TPF) have been performed in different solvents. Solvent-dependent TPA spectra of these dyes were measured with open aperture z-scan method and compared to their respective single-photon spectra at equivalent energies. In the TPA spectra, relative peak intensities and positions are highly solvent dependent, which could be a result of vibronic couplings that depend on solvent environment. Measured TPA cross-sections of rhodamine dyes are consistently higher in nonpolar solvents. Certain complementary and similarity between TPA and TPF are also elucidated. Finally, a two-photon figure-of-merit is presented for these dyes in different solvents as a function of wavelength.


Enhanced photocatalytic activity of BiVO4 by co-grafting of metal ions and combining with CuBi2O4
In order to improve photocatalytic activity of BiVO4, the co-grafting effects of two kinds of co-catalysts for electron and hole separations were examined. At first, stabilization of electrons in BiVO4 by grafting Fe3+ was confirmed by analyzing the formation of O2− and H2O2 as reduction intermediates of O2. When BiVO4 was co-grafted with Fe3+ and CoPi as an electron separator and a hole separator, respectively, its photocatalytic activity for decomposition of gaseous acetaldehyde with visible light (470nm LED) was enhanced compared to the BiVO4 grafted only by either co-catalyst. This indicated that co-grafting is effective to increase photocatalytic activity because electron and hole were effectively taken out of the BiVO4. Furthermore, by combined with CuBi2O4, a p-type semiconductor, the photocatalytic activity of BiVO4 was also increased. This is because holes and electrons, which were generated in the both semiconductors, were successfully separated in BiVO4 and CuBi2O4, respectively, due to combination of electrons in the BiVO4 with holes in the CuBi2O4. To promote the reaction between electrons in BiVO4 and holes in CuBi2O4, we examined co-grafting effects of two kinds of co-catalyst to the composite by preparing the Cu/CuBi2O4–CoPi/BiVO4 photocatalyst. The photocatalytic activity was further enhanced when it was prepared in a suitable procedure that enables us to graft the reduction and oxidation co-catalysts only at each site.


Continuous sonification enhances adequacy of interactions in peripheral process monitoring
As many users who are charged with process monitoring need to focus mainly on other work while performing monitoring as a secondary task, monitoring systems that purely rely on visual means are often not well suited for this purpose. Sonification, the presentation of data as (non-speech) sound, has proven in several studies that it can help in guiding the user's attention, especially in scenarios where process monitoring is performed in parallel with a different, main task. However, there are several aspects that have not been investigated in this area so far, for example if a continuous soundscape can guide the user's attention better than one that is based on auditory cues. We have developed a system that allows reproducible research to answer such questions. In this system, the participants’ performance both for the main task (simulated by simple arithmetic problems) and for the secondary task (a simulation of a production process) can be measured in a more fine-grained manner than has been the case for existing research in this field. In a within-subject study (n=18), we compared three monitoring conditions – visual only, visual + auditory alerts and a condition combining the visual mode with continuous sonification of process events based on a forest soundscape. Participants showed significantly higher process monitoring performances in the continuous sonification condition, compared to the other two modes. The performance in the main task was at the same time not significantly affected by the continuous sonification.As many users who are charged with process monitoring need to focus mainly on other work while performing monitoring as a secondary task, monitoring systems that purely rely on visual means are often not well suited for this purpose. Sonification, the presentation of data as (non-speech) sound, has proven in several studies that it can help in guiding the user's attention, especially in scenarios where process monitoring is performed in parallel with a different, main task. However, there are several aspects that have not been investigated in this area so far, for example if a continuous soundscape can guide the user's attention better than one that is based on auditory cues. We have developed a system that allows reproducible research to answer such questions. In this system, the participants’ performance both for the main task (simulated by simple arithmetic problems) and for the secondary task (a simulation of a production process) can be measured in a more fine-grained manner than has been the case for existing research in this field. In a within-subject study (n=18), we compared three monitoring conditions – visual only, visual + auditory alerts and a condition combining the visual mode with continuous sonification of process events based on a forest soundscape. Participants showed significantly higher process monitoring performances in the continuous sonification condition, compared to the other two modes. The performance in the main task was at the same time not significantly affected by the continuous sonification.


Thermodynamic stability and electronic structure of η-Ni6Nb(Al,Ti) from first principles
First principles calculations in combination with special quasirandom structures are used to investigate the thermodynamic stability and electronic structure of a partially ordered hexagonal phase with chemistry Ni6Nb(Al,Ti) observed in Allvac 718Plus. The results agree with the experimental observations by confirming the structural stability of the alloy over a wide range of compositions. At finite temperature, vibrational and configurational contributions to the free energy stabilize a competing orthorhombic phase, which is shown to become energetically favourable for high Ti concentrations.


Downscaling near-surface atmospheric fields with multi-objective Genetic Programming
We present a new Genetic Programming based method to derive downscaling rules (i.e., functions or short programs) generating realistic high-resolution fields of atmospheric state variables near the surface given coarser-scale atmospheric information and high-resolution information on land surface properties. Such downscaling rules can be applied in coupled subsurface-land surface-atmosphere simulations or to generate high-resolution atmospheric input data for offline applications of land surface and subsurface models. Multiple features of the high-resolution fields, such as the spatial distribution of subgrid-scale variance, serve as objectives. The downscaling rules take an interpretable form and contain on average about 5 mathematical operations. The method is applied to downscale 10 m-temperature fields from 2.8 km to 400 m grid resolution. A large part of the spatial variability is reproduced, also in stable nighttime situations, which generate very heterogeneous near-surface temperature fields in regions with distinct topography.We present a new Genetic Programming based method to derive downscaling rules (i.e., functions or short programs) generating realistic high-resolution fields of atmospheric state variables near the surface given coarser-scale atmospheric information and high-resolution information on land surface properties. Such downscaling rules can be applied in coupled subsurface-land surface-atmosphere simulations or to generate high-resolution atmospheric input data for offline applications of land surface and subsurface models. Multiple features of the high-resolution fields, such as the spatial distribution of subgrid-scale variance, serve as objectives. The downscaling rules take an interpretable form and contain on average about 5 mathematical operations. The method is applied to downscale 10 m-temperature fields from 2.8 km to 400 m grid resolution. A large part of the spatial variability is reproduced, also in stable nighttime situations, which generate very heterogeneous near-surface temperature fields in regions with distinct topography.


Modeling the potential effects of sea-level rise on the coast of New York: Integrating mechanistic accretion and stochastic uncertainty
The Sea-Level Affecting Marshes Model was applied to coastal New York State at a 5 m horizontal resolution to investigate marsh conservation and potential migration under multiple sea-level rise scenarios. Feedbacks between sea-level rise and marsh accretion rates based on mechanistic modeling were included. Simulation results predict extensive marsh losses in microtidal regimes behind the barrier islands of Long Island, vulnerable dry lands on barrier islands, and opportunities for upland migration of coastal marshes. Results also indicate changes in the composition of marsh types. Confidence of predictions due to model parameter variabilities and spatial data error were estimated with the uncertainty estimation module. Likelihood maps of land cover changes were produced. Uncertainty results suggest that variability in land cover projections is mostly due to the wide range in potential sea-level rise signals by 2100 while impact from uncertainties in model parameters, spatial data errors and linked models is less significant.The Sea-Level Affecting Marshes Model was applied to coastal New York State at a 5 m horizontal resolution to investigate marsh conservation and potential migration under multiple sea-level rise scenarios. Feedbacks between sea-level rise and marsh accretion rates based on mechanistic modeling were included. Simulation results predict extensive marsh losses in microtidal regimes behind the barrier islands of Long Island, vulnerable dry lands on barrier islands, and opportunities for upland migration of coastal marshes. Results also indicate changes in the composition of marsh types. Confidence of predictions due to model parameter variabilities and spatial data error were estimated with the uncertainty estimation module. Likelihood maps of land cover changes were produced. Uncertainty results suggest that variability in land cover projections is mostly due to the wide range in potential sea-level rise signals by 2100 while impact from uncertainties in model parameters, spatial data errors and linked models is less significant.


Model evaluation in relation to soil N2O emissions: An algorithmic method which accounts for variability in measurements and possible time lags
The loss of nitrogen from fertilised soils in the form of nitrous oxide (N2O) is a side effect of modern agriculture and the focus of many model-based studies. Due to the spatial and temporal heterogeneity of soil N2O emissions, the measured data can introduce limitations to the use of those statistical methods that are most commonly employed in the evaluation of model performance. In this paper, we describe these limitations and present an algorithm developed to address them. We implement the algorithm using simulated and measured N2O data from two UK arable sites. We show that possible time lags between the measured and simulated data can affect model evaluation and that their consideration in the evaluation process can reduce measures such as the Mean Squared Error (MSE) by 30%. We also analyse the algorithm's results to identify patterns in the estimated lags and to narrow down their possible causes.The loss of nitrogen from fertilised soils in the form of nitrous oxide (N2O) is a side effect of modern agriculture and the focus of many model-based studies. Due to the spatial and temporal heterogeneity of soil N2O emissions, the measured data can introduce limitations to the use of those statistical methods that are most commonly employed in the evaluation of model performance. In this paper, we describe these limitations and present an algorithm developed to address them. We implement the algorithm using simulated and measured N2O data from two UK arable sites. We show that possible time lags between the measured and simulated data can affect model evaluation and that their consideration in the evaluation process can reduce measures such as the Mean Squared Error (MSE) by 30%. We also analyse the algorithm's results to identify patterns in the estimated lags and to narrow down their possible causes.


An enhanced SWAT wetland module to quantify hydraulic interactions between riparian depressional wetlands, rivers and aquifers
This study develops a modified version of the Soil and Water Assessment Tool (SWAT) designed to better represent riparian depressional wetlands (SWATrw). It replaces existing unidirectional hydrological interactions between a wetland and a river/aquifer with a more robust bidirectional approach based on hydraulic principles. SWATrw incorporates a more flexible wetland morphometric formula and a connecting channel concept to model wetland-river interactions. SWAT and SWATrw were tested for the Barak-Kushiyara River Basin (Bangladesh and India). Although the two models showed small differences in simulated stream flow, SWATrw outperformed SWAT in reproducing river stages and the pre-monsoon river-spills into riparian wetlands. SWATrw showed that the observed presence of dry season water in the wetland was due to reduced seepage to the local groundwater table whilst continuous seepage simulated by SWAT resulted in the wetland drying out completely. The new model therefore more closely simulates the hydrological interactions between wetlands, rivers and groundwater.This study develops a modified version of the Soil and Water Assessment Tool (SWAT) designed to better represent riparian depressional wetlands (SWATrw). It replaces existing unidirectional hydrological interactions between a wetland and a river/aquifer with a more robust bidirectional approach based on hydraulic principles. SWATrw incorporates a more flexible wetland morphometric formula and a connecting channel concept to model wetland-river interactions. SWAT and SWATrw were tested for the Barak-Kushiyara River Basin (Bangladesh and India). Although the two models showed small differences in simulated stream flow, SWATrw outperformed SWAT in reproducing river stages and the pre-monsoon river-spills into riparian wetlands. SWATrw showed that the observed presence of dry season water in the wetland was due to reduced seepage to the local groundwater table whilst continuous seepage simulated by SWAT resulted in the wetland drying out completely. The new model therefore more closely simulates the hydrological interactions between wetlands, rivers and groundwater.


A weighted cellular automata 2D inundation model for rapid flood analysis
To achieve fast flood modelling for large-scale problems, a two-dimensional cellular automata based model was developed. This model employs simple transition rules and a weight-based system rather than complex Shallow Water Equations. The simplified feature of cellular automata allows the model to be implemented in parallel environments, resulting in significantly improved modelling efficiency. The model has been tested using an analytical solution and four case studies and the outputs were compared to those from a widely-used commercial physically-based hydraulic model. Results show that the model is capable of simulating water-depth and velocity variables with reasonably good agreement with the benchmark model, using only a fraction of the computational time and memory. In the case of the real world example, the proposed model run times are up to 8 times faster. The rapid and accurate attributes of the model have demonstrated its applicability for quick flood analysis in large modelling systems.To achieve fast flood modelling for large-scale problems, a two-dimensional cellular automata based model was developed. This model employs simple transition rules and a weight-based system rather than complex Shallow Water Equations. The simplified feature of cellular automata allows the model to be implemented in parallel environments, resulting in significantly improved modelling efficiency. The model has been tested using an analytical solution and four case studies and the outputs were compared to those from a widely-used commercial physically-based hydraulic model. Results show that the model is capable of simulating water-depth and velocity variables with reasonably good agreement with the benchmark model, using only a fraction of the computational time and memory. In the case of the real world example, the proposed model run times are up to 8 times faster. The rapid and accurate attributes of the model have demonstrated its applicability for quick flood analysis in large modelling systems.


Barriers and facilitators to Electronic Medical Record (EMR) use in an urban slum
ObjectiveRapid urbanization has led to the growth of urban slums and increased healthcare burdens for vulnerable populations. Electronic Medical Records (EMRs) have the potential to improve continuity of care for slum residents, but their implementation is complicated by technical and non-technical limitations. This study sought practical insights about facilitators and barriers to EMR implementation in urban slum environments.MethodDescriptive qualitative method was used to explore staff perceptions about a recent open-source EMR deployment in two primary care clinics in Kibera, Nairobi. Participants were interviewed using open-ended, semi-structured questions. Content analysis was used when exploring transcribed data.ResultsThree major themes – systems, software, and social considerations – emerged from content analysis, with sustainability concerns prevailing. Although participants reported many systems (e.g., power, network, Internet, hardware, interoperability) and software (e.g., data integrity, confidentiality, function) challenges, social factors (e.g., identity management, training, use incentives) appeared the most important impediments to sustainability.DiscussionThese findings are consistent with what others have reported, especially the importance of practical barriers to EMR deployments in resource-constrained settings. Other findings contribute unique insights about social determinants of EMR impact in slum settings, including the challenge of multiple-identity management and development of meaningful incentives to staff compliance.ConclusionsThis study exposes front-line experiences with opportunities and shortcomings of EMR implementations in urban slum primary care clinics. Although the promise is great, there are a number of unique system, software and social challenges that EMR advocates should address before expecting sustainable EMR use in resource-constrained settings.


Exploiting user interest similarity and social links for micro-blog forwarding in mobile opportunistic networks
Micro-blogging services have recently been experiencing increasing success among Web users. Different to traditional online social applications, micro-blogs are lightweight, require small cognitive effort and help share real-time information about personal activities and interests. In this article, we explore scalable pushing protocols that are particularly suited for the delivery of this type of service in a mobile pervasive environment. Here, micro-blog updates are generated and carried by mobile (smart-phone type) devices and are exchanged through opportunistic encounters. We enhance primitive push mechanisms using social information concerning the interests of network nodes as well as the frequency of encounters with them. This information is collected and shared dynamically, as nodes initially encounter each other and exchange their preferences, and directs the forwarding of micro-blog updates across the network. Also incorporated is the spatiotemporal scope of the updates, which is only partially considered in current Internet services.We introduce several new protocol variants that differentiate the forwarding strategy towards interest-similar and frequently encountered nodes, as well as the amount of updates forwarded upon each encounter. In all cases, the proposed scheme outperforms the basic flooding dissemination mechanism in delivering high numbers of micro-blog updates to the nodes interested in them. Our extensive evaluation highlights how use can be made of different amounts of social information to trade performance with complexity and computational effort. However, hard performance bounds appear to be set by the level of coincidence between interest-similar node communities and meeting groups emerging due to the mobility patterns of the nodes.


Proactive Highly Ambulatory Sensor Routing (PHASeR) protocol for mobile wireless sensor networks
This paper presents a novel multihop routing protocol for mobile wireless sensor networks called PHASeR (Proactive Highly Ambulatory Sensor Routing). The proposed protocol uses a simple hop-count metric to enable the dynamic and robust routing of data towards the sink in mobile environments. It is motivated by the application of radiation mapping by unmanned vehicles, which requires the reliable and timely delivery of regular measurements to the sink. PHASeR maintains a gradient metric in mobile environments by using a global TDMA MAC layer. It also uses the technique of blind forwarding to pass messages through the network in a multipath manner. PHASeR is analysed mathematically based on packet delivery ratio, average packet delay, throughput and overhead. It is then simulated with varying mobility, scalability and traffic loads. The protocol gives good results over all measures, which suggests that it may also be suitable for a wider array of emerging applications.


Superconductivity in transuranium elements and compounds
RésuméNous présentons ici un aperçu des propriétés des supraconducteurs transuraniens, mais aussi des analogues transuraniens (non supraconducteurs) des supraconducteurs à base d'uranium. Nous examinons brièvement la supraconductivité dans les éléments d'actinides et les composés d'uranium, puis nous présentons en particulier la famille des composés PuTX5 (T=Co,Rh, X=Ga,In), la série la plus étendue de supraconducteurs parmi les actinides ainsi que NpPd5Al2, le seul supraconducteur au neptunium connu à ce jour. Les effets de la substitution chimique, du vieillissement et de la pression sur les propriétés des supraconducteurs transuraniens sont également discutés.


Wide spectrum solar energy harvesting through an integrated photovoltaic and thermoelectric system
This paper proposes a power system concept that integrates photovoltaic (PV) and thermoelectric (TE) technologies to harvest solar energy from a wide spectral range. By introduction of the ‘spectrum beam splitting’ technique, short wavelength solar radiation is converted directly into electricity in the PV cells, while the long wavelength segment of the spectrum is used to produce moderate to high temperature thermal energy, which then generates electricity in the TE device. To overcome the intermittent nature of solar radiation, the system is also coupled to a thermal energy storage unit. A systematic analysis of the integrated system is carried out, encompassing the system configuration, material properties, thermal management, and energy storage aspects. We have also attempted to optimize the integrated system. The results indicate that the system configuration and optimization are the most important factors for high overall efficiency.


One-factor-at-a-time (OFAT) optimization of xylanase production from Trichoderma viride-IR05 in solid-state fermentation
The present study dealt with the production of enzyme xylanase by solid substrate fermentation using Trichoderma viride-IR05. Different substrates such as wheat bran, rice polish, rice husk, soybean meal, sunflower meal, sugarcane bagasse or corn cobs were evaluated for enzyme production. Of all the substrates evaluated, sugarcane bagasse was found to be best for enzyme synthesis. The substrate, sugarcane bagasse pretreated biologically, 2% H2SO4, 2.5% KOH or 3%H2O2. However 2.5% KOH gave maximum yield of enzyme as evidenced by the SEM analysis of the pretreated substrate. The cultural conditions were optimized for the production of xylanase in 250 ml Erlenmeyer flask such as incubation period (seven days), substrate concentration (10 g), liquid to solid ratio (11:10), initial pH of diluent (4.5), incubation temperature (30 °C) with inoculum size of 10%. Further supplementation of xylose, NaNO3 or tryptone and tween-80 as additional carbon source, nitrogen and surfactant improved (72.4 ± 1.42 U/g) the titer of xylanase by T. viride-IR05, respectively.The present study dealt with the production of enzyme xylanase by solid substrate fermentation using Trichoderma viride-IR05. Different substrates such as wheat bran, rice polish, rice husk, soybean meal, sunflower meal, sugarcane bagasse or corn cobs were evaluated for enzyme production. Of all the substrates evaluated, sugarcane bagasse was found to be best for enzyme synthesis. The substrate, sugarcane bagasse pretreated biologically, 2% H2SO4, 2.5% KOH or 3%H2O2. However 2.5% KOH gave maximum yield of enzyme as evidenced by the SEM analysis of the pretreated substrate. The cultural conditions were optimized for the production of xylanase in 250 ml Erlenmeyer flask such as incubation period (seven days), substrate concentration (10 g), liquid to solid ratio (11:10), initial pH of diluent (4.5), incubation temperature (30 °C) with inoculum size of 10%. Further supplementation of xylose, NaNO3 or tryptone and tween-80 as additional carbon source, nitrogen and surfactant improved (72.4 ± 1.42 U/g) the titer of xylanase by T. viride-IR05, respectively.


Characterization of cochlear implant artifacts in electrically evoked auditory steady-state responses
ObjectiveElectrically evoked auditory steady-state responses (EASSRs) are neural potentials measured in the electroencephalogram (EEG) in response to periodic pulse trains presented, for example, through a cochlear implant (CI). EASSRs could potentially be used for objective CI fitting. However, EEG signals are contaminated with electrical CI artifacts. In this paper, we characterized the CI artifacts for monopolar mode stimulation and evaluated at which pulse rate, linear interpolation over the signal part contaminated with CI artifact is successful.MethodsCI artifacts were characterized by means of their amplitude growth functions and duration.ResultsCI artifact durations were between 0.7 and 1.7ms, at contralateral recording electrodes. At ipsilateral recording electrodes, CI artifact durations are range from 0.7 to larger than 2ms.ConclusionAt contralateral recording electrodes, the artifact was shorter than the interpulse interval across subjects for 500pps, which was not always the case for 900pps.SignificanceCI artifact-free EASSRs are crucial for reliable CI fitting and neuroscience research. The CI artifact has been characterized and linear interpolation allows to remove it at contralateral recording electrodes for stimulation at 500pps.


Validation of a microsimulation of the Port of Dover
Modelling and simulating the traffic of heavily used but secure environments such as seaports and airports are of increasing importance. Errors made when simulating these environments can have long standing economic, social and environmental implications. This article discusses issues and problems that may arise when designing a simulation strategy. Data for the Port is presented, methods for lightweight vehicle assessment that can be used to calibrate and validate simulations are also discussed along with a diagnosis of overcalibration issues. We show that decisions about where the intelligence lies in a system has important repercussions for the reliability of system statistics. Finally, conclusions are drawn about how microsimulations can be moved forward as a robust planning tool for the 21st century.


Analysing and modelling the performance of the HemeLB lattice-Boltzmann simulation environment
We investigate the performance of the HemeLB lattice-Boltzmann simulator for cerebrovascular blood flow, aimed at providing timely and clinically relevant assistance to neurosurgeons. HemeLB is optimised for sparse geometries, supports interactive use, and scales well to 32,768 cores for problems with ∼81 million lattice sites. We obtain a maximum performance of 29.5 billion site updates per second, with only an 11% slowdown for highly sparse problems (5% fluid fraction). We present steering and visualisation performance measurements and provide a model which allows users to predict the performance, thereby determining how to run simulations with maximum accuracy within time constraints.


Open-source tools for dynamical analysis of Liley's mean-field cortex model
Mean-field models of the mammalian cortex treat this part of the brain as a two-dimensional excitable medium. The electrical potentials, generated by the excitatory and inhibitory neuron populations, are described by nonlinear, coupled, partial differential equations that are known to generate complicated spatio-temporal behaviour. We focus on the model by Liley et al. (Network: Computation in Neural Systems 13 (2002) 67–113). Several reductions of this model have been studied in detail, but a direct analysis of its spatio-temporal dynamics has, to the best of our knowledge, never been attempted before. Here, we describe the implementation of implicit time-stepping of the model and the tangent linear model, and solving for equilibria and time-periodic solutions, using the open-source library PETSc. By using domain decomposition for parallelization, and iterative solving of linear problems, the code is capable of parsing some dynamics of a macroscopic slice of cortical tissue with a sub-millimetre resolution.


Flexible composition and execution of large scale applications on distributed e-infrastructures
Computer simulation is finding a role in an increasing number of scientific disciplines, concomitant with the rise in available computing power. Marshalling this power facilitates new, more effective and different research than has been hitherto possible. Realizing this inevitably requires access to computational power beyond the desktop, making use of clusters, supercomputers, data repositories, networks and distributed aggregations of these resources. The use of diverse e-infrastructure brings with it the ability to perform distributed multiscale simulations. Accessing one such resource entails a number of usability and security problems; when multiple geographically distributed resources are involved, the difficulty is compounded. In this paper we present a solution, the Application Hosting Environment,33AHE is available to download under the LGPL license from: https://sourceforge.net/projects/ahe3/. which provides a Software as a Service layer on top of distributed e-infrastructure resources. We describe the performance and usability enhancements present in AHE version 3, and show how these have led to a high performance, easy to use gateway for computational scientists working in diverse application domains, from computational physics and chemistry, materials science to biology and biomedicine.


An automated multiscale ensemble simulation approach for vascular blood flow
Cerebrovascular diseases such as brain aneurysms are a primary cause of adult disability. The flow dynamics in brain arteries, both during periods of rest and increased activity, are known to be a major factor in the risk of aneurysm formation and rupture. The precise relation is however still an open field of investigation. We present an automated ensemble simulation method for modelling cerebrovascular blood flow under a range of flow regimes. By automatically constructing and performing an ensemble of multiscale simulations, where we unidirectionally couple a 1D solver with a 3D lattice-Boltzmann code, we are able to model the blood flow in a patient artery over a range of flow regimes. We apply the method to a model of a middle cerebral artery, and find that this approach helps us to fine-tune our modelling techniques, and opens up new ways to investigate cerebrovascular flow properties.


LBP Based Fast Face Recognition System on Symbian Platform
In this paper, an implementation of a LBP (local binary pattern) based fast face recognition system on symbian platform is presented. First, face in picture taken from camera is detected using AdaBoost algorithm. Second, the pre-processing of the face is done, including eye location, geometric normalization, illumination normalization. During the face preprocessing, a rapid eye location method named ER (Eyeball Search) is proposed and implemented. Last, the improved LBP is adopted for recognition. Although the computational capability of the symbian platform is limited, the experimental results show good performance for recognition rate and time. in pressIn this paper, an implementation of a LBP (local binary pattern) based fast face recognition system on symbian platform is presented. First, face in picture taken from camera is detected using AdaBoost algorithm. Second, the pre-processing of the face is done, including eye location, geometric normalization, illumination normalization. During the face preprocessing, a rapid eye location method named ER (Eyeball Search) is proposed and implemented. Last, the improved LBP is adopted for recognition. Although the computational capability of the symbian platform is limited, the experimental results show good performance for recognition rate and time. in press
[1] K. Venkataramani, S. Qidwai, B. VijayaKumar. Face authentication from cell phone camera images with illumination and temporal variations. IEEE Trans. on Systems, 2005, vol. 35, no. 3, 411-418. [2] Shih-Wei Chu, Mei-Chen Yeh, Kwang-Ting Cheng. A Real-time, Embedded Face-Annotation System. MM’08, Vancouver, British Columbia, Canada. 2008, October 26-31. [3] S. Z. Li, A.K. Jain. Handbook of Face Recognition. Springer-Verlag. New York; 2005. [4] Ming-Hsuan Yang, David Kriegman, Narendra Ahuja. Detecting faces in images: A survey. Pattern Analysis  &  Machine Intelligence 24(1), January 2002, 34-58. [5] E. Hjelmas, B.K. Low. Face detection: A survey. Computer Vision and Image Understanding, 2001;83:236-274. [6] T. Ahonen, A. Hadid, M. Pietikainen, Face description with local binary patterns: Application to face recognition, Transactions on Pattern Analysis and Machine Intelligence, 2006; 28, no. 12, 2037-2041. [7] Ojala, T., Pietik̈ ainen, M., Harwood, D.: A comparative study of texture measures with classiﬁcation based on feature distributions. Pattern Recognition 29 (1996) 51-59. [8] Zhenhua Guo, Lei Zhang, David Zhang, and Xuanqin Mou, “Hierarchical multiscale LBP for face and palmprint recognition”, Image Processing (ICIP), 2010; 4521-4524.

A Sentence Alignment Model Based on Combined Clues and Kernel Extensional Matrix Matching Method
A sentence alignment model based on combined clues and Kernel Extensional Matrix Matching (KEMM) method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc.; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. Experimental results illustrated that our model outperforms over the Gale's system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing.A sentence alignment model based on combined clues and Kernel Extensional Matrix Matching (KEMM) method is proposed. In this model, a similarity matrix for sentence aligning is formed by the similarities of bilingual sentences calculated by the combined clues, such as lexicon, morphology, length and special symbols, etc.; then this similarity matrix is used to construct a select matrix for sentence aligning; finally, obtains the sentence alignments by KEMM. Experimental results illustrated that our model outperforms over the Gale's system on handling any types of sentence alignments, with 30% total sentence alignment error rate decreasing.
[1] W. Gale K. Church A program for aligning sentences in bilingual corpora Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics Berkeley 1991 177 184 [2] A. Elithorn R. Banerji M.A. Nagao Framework of a Mechanical Translation Between Japanese and English by Analogy Principle. Artifical and Human Inteligence New York: Elsevier Science Publishers Corporation; 1984 173 180 [3] R.D. Brown Automated Generalization of Translation Examples Proceedings of the Eighteenth International Conference on Computational Linguistics 2000 125 131 [4] Halil Altay Guvenir Ilyas Cicekli Learning Translation Templates from Examples Information Systems 23 6 1998 353 363 [5] Arnold D., Balkan L., Humphreys R. Lee, Meijer S., Sadler L. Machine Translation. 1994.

Comparison of SIFT and SURF Methods for Use on Hand Gesture Recognition based on Depth Map
In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.In this paper a comparison between two popular feature extraction methods is presented. Scale-invariant feature transform (or SIFT) is the first method. The Speeded up robust features (or SURF) is presented as second. These two methods are tested on set of depth maps. Ten defined gestures of left hand are in these depth maps. The Microsoft Kinect camera is used for capturing the images [1]. The Support vector machine (or SVM) is used as classification method. The results are accuracy of SVM prediction on selected images.
[1] Yujie Shen, Zhonghua Hao, Pengfei Wang, Shiwei Ma, Wanquan Liu, A Novel Human Detection Approach Based on Depth Map via Kinect. Computer Vision and Pattern Recognition Workshops (CVPRW); 2013 IEEE Conference on , vol., no., pp.535,541, 23-28 June 2013. [2] Panwar M, Hand gesture recognition based on shape parameters. Computing, Communication and Applications (ICCCA); 2012 International Conference on , vol., no., pp.1,6, 22-24 Feb. 2012. [3] Jalal A, Uddin M Z, Kim T–S, Depth video-based human activity recognition system using translation and scaling invariant features for life logging at smart home. Consumer Electronics; IEEE Transactions on , vol.58, no.3, pp.863,871; August 2012. [4] Wenjun T, Chengdong W, Shuying Z, Li J, Dynamic hand gesture recognition using motion trajectories and key frames. Advanced Computer Control (ICACC); 2010 2nd International Conference on , vol.3, no., pp.163,167, 27-29 March 2010. [5] S Matuska, R Hudec, M Benco, M Zachariasova, Opponent colour descriptors in object recognition. 15th International Conference on Research in Telecommunication Technologies; Senec Slovakia; ISBN 978-80-227-4026-5; 11-13 Sep. 2013. [6] Han X, Wenhao H, Kui Y, Feng W, Real-time scene recognition on embedded system with SIFT keypoints and a new descriptor. Mechatronics and Automation (ICMA); 2013 IEEE International Conference on , vol., no., pp.1317,1324, 4-7 Aug. 2013. [7] Zhang H. Hu Q, Fast image matching based-on improved SURF algorithm. Electronics; Communications and Control (ICECC), 2011 International Conference on , vol., no., pp.1460,1463, 9-11 Sept. 2011. [8] Soliman O S, Mahmoud A S, A classification system for remote sensing satellite images using support vector machine with non-linear kernel functions. Informatics and Systems (INFOS), 2012 8th International Conference on , vol., no., pp.BIO-181,BIO-187, 14-16 May 2012. [9] Sykora P, Hudec R, Benco M, 3D Shape-Motion Detection. TRANSCOM 2013; Zilina; ISBN: 978-80-554-0692-3; pp.111,114; 24-26 June 2013.

Investigation of dynamic behavior of hot mix asphalt containing waste materials; case study: Glass cullet
This paper aims to study the performance of asphalt concrete in which some of the fractional fine aggregate is substituted with crushed glass material. This asphalt containing glass cullet as an aggregate is called “glasphalt” and has been used as a means of disposing surplus waste glass since the 1960s. In this study, some important dynamic properties of glasphalt, including fatigue life, stiffness modulus and creep compliance, are investigated. The data show that the dynamic properties of glass–asphalt concrete are improved in comparison with ordinary asphalt concrete. The research has demonstrated that it is feasible to use and recycle waste glass in asphalt concrete.


